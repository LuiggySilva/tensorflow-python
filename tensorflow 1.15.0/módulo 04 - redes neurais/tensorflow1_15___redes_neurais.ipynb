{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow1_15___redes_neurais.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRigdBMdD-wK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOl6wfZ30Vtv",
        "colab_type": "text"
      },
      "source": [
        "> # **Aula 016** - Perceptron de uma camada - **Tensorflow: Redes Neurais - Classificação e Regressão**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOQhQyaaKWme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def step_function(x):\n",
        "  # x >= 1 return 1.0 else return 0.0\n",
        "  return tf.cast( tf.to_float(tf.math.greater_equal(x, 1)) , tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ0ebf_Y0B1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# - exemplo: porta lógica OR -\n",
        "\n",
        "'''\n",
        " | A | B | A or B |\n",
        " | 0 | 0 |   0    | \n",
        " | 0 | 1 |   1    |  \n",
        " | 1 | 0 |   1    |  \n",
        " | 1 | 1 |   1    |\n",
        "'''\n",
        "\n",
        "# entrada\n",
        "X = np.array([[0.0, 0.0],\n",
        "              [0.0, 1.0],\n",
        "              [1.0, 0.0],\n",
        "              [1.0, 1.0]])\n",
        "\n",
        "# saida\n",
        "y = np.array([[0.0],\n",
        "              [1.0],\n",
        "              [1.0],\n",
        "              [1.0]])\n",
        "\n",
        "# pesos\n",
        "# [2, 1] = tamanho da matriz de zeros 2 linhas x 1 coluna - 2 linhas por conta das duas entradas\n",
        "W = tf.Variable(tf.zeros([2, 1], dtype = tf.float64))\n",
        "\n",
        "camada_saida = tf.matmul(X, W)\n",
        "camada_saida_ativacao = step_function(camada_saida)\n",
        "\n",
        "# calculo e ajuste dos erros - peso(n+1) = peso(n) + (taxa_aprendizagem * entrada * erro) -\n",
        "erro = tf.subtract(y, camada_saida_ativacao)\n",
        "\n",
        "# transpose_a = True -> realizando o calculo com a matriz transposta de X \n",
        "# para não ter erro com as dimenções das matrizes no cálculo\n",
        "delta = tf.matmul(X, erro, transpose_a=True)\n",
        "\n",
        "# tf.assigin(W, ...) -> permite que a váriavel W seja atualizada durante a execução\n",
        "treinamento = tf.assign(W, tf.add(W, tf.multiply(delta, 0.1)) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y1WZEhI2Plt",
        "colab_type": "code",
        "outputId": "0110bd30-8b7e-4453-8b96-72e12151779e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        }
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "\n",
        "  print(f'X\\n{X}', end='\\n'*2)\n",
        "  print(f'y\\n{y}', end='\\n'*2)  \n",
        "\n",
        "  print(f'W\\n{sess.run(W)}', end='\\n'*2)\n",
        "  print(f'camada_saida\\n{sess.run(camada_saida)}', end='\\n'*2)\n",
        "  print(f'camada_saida_ativacao\\n{sess.run(camada_saida_ativacao)}', end='\\n'*2)\n",
        "  \n",
        "  print(f'erro\\n{sess.run(erro)}', end='\\n'*2)\n",
        "  print(f'treinamento\\n{sess.run(treinamento)}', end='\\n'*2)\n",
        "\n",
        "  epochs = 0\n",
        "  for i in range(15):\n",
        "    epochs += 1\n",
        "    # o erro_total é um vetor com os erros de cada registro\n",
        "    erro_total, _ = sess.run([erro, treinamento])\n",
        "    erro_soma = tf.reduce_sum(erro_total)\n",
        "\n",
        "    print(f'época {epochs} - erro_total: {sess.run(erro_soma)}')\n",
        "\n",
        "    if(erro_soma.eval() == 0.0):\n",
        "      break\n",
        "  \n",
        "  W_final = sess.run(W)\n",
        "  print( '\\n' + f'W_final\\n{W_final}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X\n",
            "[[0. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 1.]]\n",
            "\n",
            "y\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "\n",
            "W\n",
            "[[0.]\n",
            " [0.]]\n",
            "\n",
            "camada_saida\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "\n",
            "camada_saida_ativacao\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "\n",
            "erro\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "\n",
            "treinamento\n",
            "[[0.2]\n",
            " [0.2]]\n",
            "\n",
            "época 1 - erro_total: 3.0\n",
            "época 2 - erro_total: 3.0\n",
            "época 3 - erro_total: 2.0\n",
            "época 4 - erro_total: 2.0\n",
            "época 5 - erro_total: 2.0\n",
            "época 6 - erro_total: 2.0\n",
            "época 7 - erro_total: 0.0\n",
            "\n",
            "W_final\n",
            "[[1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-QANERJQ8JF",
        "colab_type": "code",
        "outputId": "15dcaaad-141c-42e1-e784-30f1450e6e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "# testando a rede neural\n",
        "\n",
        "camada_saida_teste = tf.matmul(X, W_final)\n",
        "camada_saida_ativacao_teste = step_function(camada_saida_teste)\n",
        "\n",
        "print(' - teste do exemplo da porta lógica OR - \\n')\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  print(f'teste com entrada\\n{X}' + '\\n'*2 + f'pesos\\n{W_final}' + '\\n'*2 + f'resultado\\n{sess.run(camada_saida_ativacao_teste)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - teste do exemplo da porta lógica OR - \n",
            "\n",
            "teste com entrada\n",
            "[[0. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 1.]]\n",
            "\n",
            "pesos\n",
            "[[1.]\n",
            " [1.]]\n",
            "\n",
            "resultado\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3_HyXylSWfI",
        "colab_type": "text"
      },
      "source": [
        "> # **Aula 017** - Classificação binária XOR - **Tensorflow: Redes Neurais - Classificação e Regressão**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzzYaHlUSfzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# - exemplo: porta lógica XOR - problema não linearmente separavel\n",
        "\n",
        "'''\n",
        " | A | B | A xor B |\n",
        " | 0 | 0 |    0    | \n",
        " | 0 | 1 |    1    |  \n",
        " | 1 | 0 |    1    |  \n",
        " | 1 | 1 |    0    |\n",
        "'''\n",
        "\n",
        "'''\n",
        "Estrutura da rede neural implementada abaixo (sem o BIAS)\n",
        "\n",
        "E = Entrada | O = Camada oculta | S = Saida\n",
        "\n",
        "  E    O    S\n",
        "       ◯ ↘\n",
        "  ◯ ⇶            \n",
        "       ◯ →  □□\n",
        "  ◯ ⇶           \n",
        "       ◯ ↗\n",
        "\n",
        "'''\n",
        "\n",
        "# entrada\n",
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "\n",
        "# saida\n",
        "y = np.array([[0],\n",
        "              [1],\n",
        "              [1],\n",
        "              [0]])\n",
        "\n",
        "neuronios_entrada = 2\n",
        "neuronios_camada_oculta = 3\n",
        "neuronios_saida = 1\n",
        "\n",
        "# pesos\n",
        "W = {\n",
        "  'oculta': tf.Variable(tf.random_normal([neuronios_entrada, neuronios_camada_oculta]), name='w_camada_oculta'),\n",
        "  'saida': tf.Variable(tf.random_normal([neuronios_camada_oculta, neuronios_saida]), name='w_camada_saida')\n",
        "}\n",
        "\n",
        "bias = {\n",
        "    'oculta': tf.Variable(tf.random_normal([neuronios_camada_oculta]), name='w_bias_oculta'),\n",
        "    'saida': tf.Variable(tf.random_normal([neuronios_saida]), name='w_bias_saida')\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afzTyj4VXWtX",
        "colab_type": "code",
        "outputId": "d194899a-5c34-425b-fd7a-5daebda96fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  print(f'w_camada_oculta\\n{sess.run(W[\"oculta\"])}', end='\\n'*2)\n",
        "  print(f'w_camada_saida\\n{sess.run(W[\"saida\"])}', end='\\n'*2)\n",
        "\n",
        "  print(f'w_bias_camada_oculta\\n{sess.run(bias[\"oculta\"])}', end='\\n'*2)\n",
        "  print(f'w_bias_camada_saida\\n{sess.run(bias[\"saida\"])}', end='\\n'*2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w_camada_oculta\n",
            "[[-1.5901126   0.6113387   1.2026505 ]\n",
            " [-2.6637514  -0.07413919  1.1995958 ]]\n",
            "\n",
            "w_camada_saida\n",
            "[[-1.2891818 ]\n",
            " [-1.1485958 ]\n",
            " [ 0.40277454]]\n",
            "\n",
            "w_bias_camada_oculta\n",
            "[ 0.10380564 -0.84043133  0.23701848]\n",
            "\n",
            "w_bias_camada_saida\n",
            "[-0.7665538]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jDnCLpIZzVD",
        "colab_type": "code",
        "outputId": "30f9a288-c33d-4b63-9d33-4137eb7b72ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "xph = tf.placeholder(tf.float32, [len(X), neuronios_entrada], name='xph')\n",
        "yph = tf.placeholder(tf.float32, [len(y), neuronios_saida], name='yph')\n",
        "\n",
        "camada_oculta = tf.add(bias['oculta'], tf.matmul(xph, W['oculta']))\n",
        "camada_oculta_ativacao = tf.sigmoid(camada_oculta)\n",
        "\n",
        "camada_saida = tf.add(bias['saida'], tf.matmul(camada_oculta_ativacao, W['saida']))\n",
        "camada_saida_ativacao = tf.sigmoid(camada_saida)\n",
        "\n",
        "erro = tf.losses.mean_squared_error(yph, camada_saida_ativacao)\n",
        "otimizador = tf.train.GradientDescentOptimizer(learning_rate=0.3).minimize(erro)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  print(f'camada_oculta\\n{sess.run(camada_oculta_ativacao, feed_dict={xph:X})}', end='\\n'*2)\n",
        "  print(f'camada_saida\\n{sess.run(camada_saida_ativacao, feed_dict={xph:X})}', end='\\n'*2)\n",
        "\n",
        "  for epochs in range(10000):\n",
        "    erro_medio = 0\n",
        "    _, custo = sess.run([otimizador, erro], feed_dict={xph:X, yph:y})\n",
        "    \n",
        "    if(epochs % 200 == 0):\n",
        "      erro_medio += custo / 4\n",
        "      print(f'erro_medio - {erro_medio}')\n",
        "  \n",
        "  W_final, bias_final = sess.run([W, bias])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "camada_oculta\n",
            "[[0.43556595 0.5055324  0.9134172 ]\n",
            " [0.63499796 0.5251287  0.6701123 ]\n",
            " [0.5461176  0.767557   0.9328738 ]\n",
            " [0.73064405 0.7812622  0.7279597 ]]\n",
            "\n",
            "camada_saida\n",
            "[[0.5233755 ]\n",
            " [0.45381576]\n",
            " [0.548393  ]\n",
            " [0.4855935 ]]\n",
            "\n",
            "erro_medio - 0.06324931979179382\n",
            "erro_medio - 0.06230480223894119\n",
            "erro_medio - 0.06136132776737213\n",
            "erro_medio - 0.059779487550258636\n",
            "erro_medio - 0.05704326182603836\n",
            "erro_medio - 0.0527028813958168\n",
            "erro_medio - 0.04682537540793419\n",
            "erro_medio - 0.03934159874916077\n",
            "erro_medio - 0.029795270413160324\n",
            "erro_medio - 0.020316436886787415\n",
            "erro_medio - 0.013413483276963234\n",
            "erro_medio - 0.009137379005551338\n",
            "erro_medio - 0.006564868614077568\n",
            "erro_medio - 0.004962650127708912\n",
            "erro_medio - 0.0039121960289776325\n",
            "erro_medio - 0.0031884736381471157\n",
            "erro_medio - 0.0026679623406380415\n",
            "erro_medio - 0.002279856475070119\n",
            "erro_medio - 0.0019816490821540356\n",
            "erro_medio - 0.0017466777935624123\n",
            "erro_medio - 0.001557576353661716\n",
            "erro_medio - 0.001402617315761745\n",
            "erro_medio - 0.001273660222068429\n",
            "erro_medio - 0.0011648985091596842\n",
            "erro_medio - 0.0010720936115831137\n",
            "erro_medio - 0.0009920878801494837\n",
            "erro_medio - 0.0009224897949025035\n",
            "erro_medio - 0.0008614539401605725\n",
            "erro_medio - 0.0008075392106547952\n",
            "erro_medio - 0.0007596046198159456\n",
            "erro_medio - 0.0007167358417063951\n",
            "erro_medio - 0.0006781920092180371\n",
            "erro_medio - 0.0006433673552237451\n",
            "erro_medio - 0.0006117636221460998\n",
            "erro_medio - 0.0005829654401168227\n",
            "erro_medio - 0.0005566232139244676\n",
            "erro_medio - 0.0005324441008269787\n",
            "erro_medio - 0.0005101792048662901\n",
            "erro_medio - 0.0004896147875115275\n",
            "erro_medio - 0.0004705687751993537\n",
            "erro_medio - 0.00045288182445801795\n",
            "erro_medio - 0.0004364168562460691\n",
            "erro_medio - 0.00042105416650883853\n",
            "erro_medio - 0.00040669034933671355\n",
            "erro_medio - 0.0003932318650186062\n",
            "erro_medio - 0.0003805980959441513\n",
            "erro_medio - 0.0003687172429636121\n",
            "erro_medio - 0.0003575255395844579\n",
            "erro_medio - 0.00034696486545726657\n",
            "erro_medio - 0.0003369847545400262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssoD_v8UaxM2",
        "colab_type": "code",
        "outputId": "25c64471-fbcb-4308-ef53-fe6d7e938f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "W_final"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'oculta': array([[ 3.9860098,  6.0558915, -1.6823252],\n",
              "        [ 3.9146874,  6.1092863, -2.125828 ]], dtype=float32),\n",
              " 'saida': array([[-8.447069 ],\n",
              "        [ 8.495853 ],\n",
              "        [ 1.0917118]], dtype=float32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTXFVS0UfKCj",
        "colab_type": "code",
        "outputId": "935e1d57-9e3e-4ae3-a2e8-8de7ae4718d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "bias_final"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'oculta': array([-6.064487 , -2.6348426,  2.9496903], dtype=float32),\n",
              " 'saida': array([-4.8013706], dtype=float32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T1hDj0GfM_d",
        "colab_type": "code",
        "outputId": "1894d3d8-f6d3-43d7-dc6f-a5a4769a1b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "# testando a rede neural\n",
        "camada_oculta_teste = tf.add(bias_final['oculta'], tf.matmul(xph, W_final['oculta']))\n",
        "camada_oculta_ativacao_teste = tf.sigmoid(camada_oculta_teste)\n",
        "\n",
        "camada_saida_teste = tf.add(bias_final['saida'], tf.matmul(camada_oculta_ativacao_teste, W_final['saida']))\n",
        "camada_saida_ativacao_teste = tf.sigmoid(camada_saida_teste)\n",
        "\n",
        "print(' - teste do exemplo da porta lógica XOR - \\n')\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  print(f'teste com entrada\\n{X}' + '\\n'*2 + f'resultado\\n{sess.run(camada_saida_ativacao_teste, feed_dict={xph:X})}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - teste do exemplo da porta lógica XOR - \n",
            "\n",
            "teste com entrada\n",
            "[[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "\n",
            "resultado\n",
            "[[0.0386075 ]\n",
            " [0.9649921 ]\n",
            " [0.9657138 ]\n",
            " [0.03672892]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtEt-UqHiLKI",
        "colab_type": "text"
      },
      "source": [
        "> # **Aula 018** - Classificação multiclasse - **Tensorflow: Redes Neurais - Classificação e Regressão**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkc4L9GLiWO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# dataset iris info - https://archive.ics.uci.edu/ml/datasets/Iris\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVGETE2Ei7tX",
        "colab_type": "code",
        "outputId": "090be562-a749-4317-866e-478ba154bb56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "iris.data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LhTxu2YjAmQ",
        "colab_type": "code",
        "outputId": "a2a2c4db-327c-4c23-fd75-4eca69ae787a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "iris.target"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr4hQsDJjDZf",
        "colab_type": "code",
        "outputId": "4c77bef2-2f1b-4cd2-aeeb-739a76785ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "iris.target_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZa05eXhjFJ8",
        "colab_type": "code",
        "outputId": "753145fa-3927-434b-faa4-627e7edcb7fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''\n",
        "Estrutura da rede neural implementada abaixo (sem o BIAS)\n",
        "\n",
        "E = Entrada | O = Camada oculta | S = Saida\n",
        "\n",
        "  E   O    S\n",
        "  ◯ ⇶ ◯ ⇶\n",
        "           ◯  \n",
        "  ◯ ⇶ ◯ ⇶        \n",
        "           ◯\n",
        "  ◯ ⇶ ◯ ⇶          \n",
        "           ◯\n",
        "  ◯ ⇶ ◯ ⇶\n",
        "\n",
        "Três neuronios de saida onde cada neuroino é uma classe e sua \n",
        "saida representa a probabilidade da entrada ser dessa classe\n",
        "'''\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# pre-processamento dos dados\n",
        "scaler_x = StandardScaler()\n",
        "X = scaler_x.fit_transform(X)\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Divide cada atributo na quantidade existente de classes para que a saida da probabilidade de cada uma seja possivel\n",
        "# o numero é o indice do numero 1 na lista\n",
        "onehot = OneHotEncoder()\n",
        "y = onehot.fit_transform(y).toarray()\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqBKr47enbph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# separando dados para treinamento e testes\n",
        "x_training, x_test, y_training, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# definindo estrutura da rede neural\n",
        "neuronios_entrada = X.shape[1]\n",
        "neuronios_camada_oculta = int(np.ceil((X.shape[1] + y.shape[1]) / 2))\n",
        "neuronios_saida = y.shape[1]\n",
        "\n",
        "# pesos\n",
        "W = {\n",
        "  'oculta': tf.Variable(tf.random_normal([neuronios_entrada, neuronios_camada_oculta])),\n",
        "  'saida': tf.Variable(tf.random_normal([neuronios_camada_oculta, neuronios_saida]))\n",
        "}\n",
        "\n",
        "bias = {\n",
        "  'oculta': tf.Variable(tf.random_normal([neuronios_camada_oculta])),\n",
        "  'saida': tf.Variable(tf.random_normal([neuronios_saida]))\n",
        "}\n",
        "\n",
        "# placeholders\n",
        "xph = tf.placeholder('float', [None, neuronios_entrada])\n",
        "yph = tf.placeholder('float', [None, neuronios_saida])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWyfNksqq1Az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp(x, W, bias):\n",
        "  camada_oculta = tf.add(tf.matmul(x, W['oculta']), bias['oculta'])\n",
        "  camada_oculta_ativacao = tf.nn.relu(camada_oculta)\n",
        "\n",
        "  camada_saida = tf.add( tf.matmul(camada_oculta_ativacao, W['saida']), bias['saida'])\n",
        "  return camada_saida"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o03pfWHrrP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo = mlp(xph, W, bias)\n",
        "erro = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits= modelo, labels= yph) )\n",
        "otimizador = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(erro)\n",
        "batch_size = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwCPxOHnR9ES",
        "colab_type": "code",
        "outputId": "585d1440-dbdf-4a12-c1db-294de5472c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(3000):\n",
        "    erro_medio = 0.0\n",
        "    batch_total = len(x_training) // batch_size\n",
        "    X_batches = np.array_split(x_training, batch_total)\n",
        "    Y_batches = np.array_split(y_training, batch_total)\n",
        "    for i in range(batch_total):\n",
        "      x_batch, y_batch = X_batches[i], Y_batches[i]\n",
        "      _, custo = sess.run([otimizador, erro], feed_dict={xph: x_batch, yph: y_batch})\n",
        "      erro_medio += custo / batch_total\n",
        "    if(epoch % 500 == 0):\n",
        "      print(f'época {epoch} - erro_medio - {erro_medio}')\n",
        "  \n",
        "  W_final, bias_final = sess.run([W, bias])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "época 0 - erro_medio - 2.390012942827665\n",
            "época 500 - erro_medio - 0.505079780633633\n",
            "época 1000 - erro_medio - 0.3937390561287219\n",
            "época 1500 - erro_medio - 0.30581688479735303\n",
            "época 2000 - erro_medio - 0.2262416120905143\n",
            "época 2500 - erro_medio - 0.16705408348486975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmr7YCmGWAEK",
        "colab_type": "code",
        "outputId": "f3196900-5ed2-4aca-ee9c-a496110136e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "W_final"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'oculta': array([[ 0.41086158, -1.8052688 , -3.1707854 ,  0.64712745],\n",
              "        [-1.7381347 , -0.88341886,  0.78772163, -0.31144103],\n",
              "        [ 1.0457602 ,  0.40577677, -1.1274812 , -1.1576369 ],\n",
              "        [ 2.1395428 , -1.3920125 , -0.62457407, -0.3982961 ]],\n",
              "       dtype=float32), 'saida': array([[-3.0093894 , -0.20861554,  0.35009098],\n",
              "        [-0.3162394 ,  0.06750153, -0.52479756],\n",
              "        [ 2.0669436 ,  0.33477852, -0.11970302],\n",
              "        [ 0.64425653,  2.1230395 , -2.0304346 ]], dtype=float32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT4hgVQ2WCH0",
        "colab_type": "code",
        "outputId": "813c8605-a20f-4bed-e6c7-45273322a809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "bias_final"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'oculta': array([1.6246567, 1.0904431, 1.4723676, 0.9861169], dtype=float32),\n",
              " 'saida': array([-0.88945186, -0.28555742, -0.28505132], dtype=float32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAEqskhtWQIu",
        "colab_type": "code",
        "outputId": "12d329d0-20ac-4d3b-bcf3-b7c155fe7ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# previsoes\n",
        "previsoes_teste = mlp(xph, W_final, bias_final)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  # previsao pura\n",
        "  r1 = sess.run(previsoes_teste, feed_dict={xph: x_test})\n",
        "  # probabilidade\n",
        "  r2 = sess.run(tf.nn.softmax(r1))\n",
        "  # dado limpo\n",
        "  r3 = sess.run(tf.arg_max(r2, 1))\n",
        "\n",
        "# comparando previsoes com a saida correta\n",
        "y_test2 = np.argmax(y_test, 1)\n",
        "\n",
        "taxa_acerto = accuracy_score(y_test2, r3)\n",
        "taxa_acerto"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOLbel3lYr_h",
        "colab_type": "text"
      },
      "source": [
        "> # **Aula 018** - Base de dados de dígitos manuscritos - **Tensorflow: Redes Neurais - Classificação e Regressão**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMcoFRfgYySZ",
        "colab_type": "code",
        "outputId": "23772fa9-399a-4806-93d4-52ab2d7af0a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = input_data.read_data_sets('mnist/', one_hot=True)\n",
        "\n",
        "len(mnist.train.images) + len(mnist.test.images)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/train-images-idx3-ubyte.gz\n",
            "Extracting mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq7uMyJ9Zt1g",
        "colab_type": "code",
        "outputId": "cfd1f213-f2fd-4da1-a99f-3b3f7f1f45b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_training = mnist.train.images\n",
        "print(f'x_training.shape - {x_training.shape}')\n",
        "print(f'x_training[0]\\n{x_training[0]}', end='\\n'*2)\n",
        "y_training = mnist.train.labels\n",
        "print(f'y_training.shape - {y_training.shape}')\n",
        "print(f'y_training[0] - {y_training[0]}', end='\\n'*2)\n",
        "x_test = mnist.test.images\n",
        "print(f'x_test.shape - {x_test.shape}')\n",
        "print(f'x_test[0]\\n{x_test[0]}', end='\\n'*2)\n",
        "y_test = mnist.test.labels\n",
        "print(f'y_test.shape - {y_test.shape}')\n",
        "print(f'y_test[0] - {y_test[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_training.shape - (55000, 784)\n",
            "x_training[0]\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.3803922  0.37647063 0.3019608\n",
            " 0.46274513 0.2392157  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.3529412\n",
            " 0.5411765  0.9215687  0.9215687  0.9215687  0.9215687  0.9215687\n",
            " 0.9215687  0.9843138  0.9843138  0.9725491  0.9960785  0.9607844\n",
            " 0.9215687  0.74509805 0.08235294 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.54901963 0.9843138  0.9960785  0.9960785\n",
            " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
            " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
            " 0.7411765  0.09019608 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.8862746  0.9960785  0.81568635 0.7803922  0.7803922  0.7803922\n",
            " 0.7803922  0.54509807 0.2392157  0.2392157  0.2392157  0.2392157\n",
            " 0.2392157  0.5019608  0.8705883  0.9960785  0.9960785  0.7411765\n",
            " 0.08235294 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.14901961 0.32156864\n",
            " 0.0509804  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.13333334 0.8352942  0.9960785  0.9960785  0.45098042 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.32941177\n",
            " 0.9960785  0.9960785  0.9176471  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.32941177 0.9960785  0.9960785\n",
            " 0.9176471  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.4156863  0.6156863  0.9960785  0.9960785  0.95294124 0.20000002\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.09803922\n",
            " 0.45882356 0.8941177  0.8941177  0.8941177  0.9921569  0.9960785\n",
            " 0.9960785  0.9960785  0.9960785  0.94117653 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.26666668 0.4666667  0.86274517 0.9960785  0.9960785\n",
            " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
            " 0.9960785  0.5568628  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.14509805 0.73333335 0.9921569\n",
            " 0.9960785  0.9960785  0.9960785  0.8745099  0.8078432  0.8078432\n",
            " 0.29411766 0.26666668 0.8431373  0.9960785  0.9960785  0.45882356\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.4431373  0.8588236  0.9960785  0.9490197  0.89019614 0.45098042\n",
            " 0.34901962 0.12156864 0.         0.         0.         0.\n",
            " 0.7843138  0.9960785  0.9450981  0.16078432 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.6627451  0.9960785\n",
            " 0.6901961  0.24313727 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.18823531 0.9058824  0.9960785\n",
            " 0.9176471  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.07058824 0.48627454 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.32941177 0.9960785  0.9960785  0.6509804  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.54509807\n",
            " 0.9960785  0.9333334  0.22352943 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.8235295  0.9803922  0.9960785  0.65882355\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.9490197  0.9960785  0.93725497 0.22352943 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.34901962 0.9843138  0.9450981\n",
            " 0.3372549  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.01960784 0.8078432  0.96470594 0.6156863  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.01568628 0.45882356\n",
            " 0.27058825 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "\n",
            "y_training.shape - (55000, 10)\n",
            "y_training[0] - [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "x_test.shape - (10000, 784)\n",
            "x_test[0]\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.32941177 0.7254902\n",
            " 0.62352943 0.5921569  0.23529413 0.14117648 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.8705883  0.9960785  0.9960785  0.9960785\n",
            " 0.9960785  0.9450981  0.77647066 0.77647066 0.77647066 0.77647066\n",
            " 0.77647066 0.77647066 0.77647066 0.77647066 0.6666667  0.20392159\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.2627451  0.44705886 0.28235295 0.44705886 0.6392157  0.89019614\n",
            " 0.9960785  0.882353   0.9960785  0.9960785  0.9960785  0.9803922\n",
            " 0.8980393  0.9960785  0.9960785  0.54901963 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.06666667 0.25882354 0.05490196\n",
            " 0.2627451  0.2627451  0.2627451  0.23137257 0.08235294 0.92549026\n",
            " 0.9960785  0.4156863  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3254902  0.9921569  0.8196079  0.07058824\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.08627451\n",
            " 0.91372555 1.         0.3254902  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.5058824  0.9960785  0.9333334\n",
            " 0.17254902 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.23137257 0.97647065 0.9960785  0.24313727 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.52156866 0.9960785\n",
            " 0.73333335 0.01960784 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.03529412 0.80392164 0.9725491  0.227451   0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.49411768\n",
            " 0.9960785  0.7137255  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.29411766 0.9843138  0.94117653 0.22352943\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.07450981\n",
            " 0.86666673 0.9960785  0.6509804  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.7960785  0.9960785  0.8588236\n",
            " 0.13725491 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.14901961 0.9960785  0.9960785  0.3019608  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.12156864 0.87843144 0.9960785\n",
            " 0.45098042 0.00392157 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.52156866 0.9960785  0.9960785  0.20392159 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.2392157  0.9490197\n",
            " 0.9960785  0.9960785  0.20392159 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.47450984 0.9960785  0.9960785  0.8588236\n",
            " 0.15686275 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.47450984 0.9960785  0.8117648  0.07058824 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "\n",
            "y_test.shape - (10000, 10)\n",
            "y_test[0] - [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEN9Aa7EbRLB",
        "colab_type": "code",
        "outputId": "06e5581a-6980-4a5c-9446-7404c0ffee4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "img_index = 6140\n",
        "plt.imshow(x_training[img_index].reshape(28,28), cmap='gray')\n",
        "plt.title(f'Classe: {np.argmax(y_training[img_index])}', fontdict={'size':25})\n",
        "print('Visualizando dado do dataset', end='\\n'*2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Visualizando dado do dataset\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAERCAYAAAC92tH2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yN568snhEDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neuronios_entrada = x_training.shape[1]\n",
        "# fórmula para quantidade de neuronios para camada oculta: x = numero_entradas + quantidade_classes // 2\n",
        "camada_oculta_1 = (x_training.shape[1] + y_training.shape[1]) // 2\n",
        "camada_oculta_2 = camada_oculta_1\n",
        "camada_oculta_3 = camada_oculta_1\n",
        "neuronios_saida =  y_training.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DGLUQAGhHW3",
        "colab_type": "code",
        "outputId": "9a2032a7-3dd9-4e52-dee2-a26f10c1e8d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "neuronios_entrada"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XguPPTNxhJEr",
        "colab_type": "code",
        "outputId": "3af8893f-c648-4d4e-ce7b-a737ad2b2c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "camada_oculta_1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "397"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODeSGUkohQEZ",
        "colab_type": "code",
        "outputId": "735584fe-cba3-4a17-eef2-47f3f0317a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "neuronios_saida"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_rYVQfAldOP",
        "colab_type": "code",
        "outputId": "badecdb2-f523-4f4d-fe2e-7de14661f491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        }
      },
      "source": [
        "'''\n",
        "Estrutura da rede neural implementada (sem o BIAS)\n",
        "\n",
        "E = Entrada | O = Camada oculta | S = Saida\n",
        "\n",
        "  E   O   O   O    S\n",
        "  ◯ ⇶ ◯ ⇶ ◯ ⇶ ◯ ⇶\n",
        "                   ◯  \n",
        "  ◯ ⇶ ◯ ⇶ ◯ ⇶ ◯ ⇶        \n",
        "                   ◯\n",
        "  ◯ ⇶ ◯ ⇶ ◯ ⇶ ◯ ⇶          \n",
        "                   ◯\n",
        "  ◯ ⇶ ◯ ⇶ ◯ ⇶ ◯ ⇶  .\n",
        "  .   .   .   .    .\n",
        "  .   .   .   .    .\n",
        "  .   .   .   .    .\n",
        "\n",
        "Entrada - 784 neuronios\n",
        "Camada oculta - 397 neuronios (em cada uma das trẽs camadas ocultas)\n",
        "Saida - 10 neuronios\n",
        "'''\n",
        "\n",
        "# pesos\n",
        "W = {\n",
        "  'oculta1': tf.Variable(tf.random_normal([neuronios_entrada, camada_oculta_1])), \n",
        "  'oculta2': tf.Variable(tf.random_normal([camada_oculta_1,   camada_oculta_2])),\n",
        "  'oculta3': tf.Variable(tf.random_normal([camada_oculta_2,   camada_oculta_3])),\n",
        "  'saida': tf.Variable(tf.random_normal([camada_oculta_3, neuronios_saida]))\n",
        "}\n",
        "\n",
        "bias = {\n",
        "  'oculta1': tf.Variable(tf.random_normal([camada_oculta_1])),\n",
        "  'oculta2': tf.Variable(tf.random_normal([camada_oculta_2])),\n",
        "  'oculta3': tf.Variable(tf.random_normal([camada_oculta_3])),\n",
        "  'saida': tf.Variable(tf.random_normal([neuronios_saida]))\n",
        "}\n",
        "\n",
        "def mlp(x, W, bias):\n",
        "  # camada_oculta_N = função_ativação ( bias (X,  multiplicando_entrada_pesos( Y, Z ) ) )\n",
        "  camada_oculta_1 = tf.nn.relu( tf.add( bias['oculta1'], tf.matmul(x, W['oculta1'] ) ) )\n",
        "  camada_oculta_2 = tf.nn.relu( tf.add( bias['oculta2'], tf.matmul(camada_oculta_1, W['oculta2'] ) ) )\n",
        "  camada_oculta_3 = tf.nn.relu( tf.add( bias['oculta3'], tf.matmul(camada_oculta_2, W['oculta3'] ) ) )\n",
        "  camada_saida = tf.add(bias['saida'], tf.matmul(camada_oculta_3, W['saida']))\n",
        "  return camada_saida\n",
        "\n",
        "xph = tf.placeholder('float', [None, neuronios_entrada])\n",
        "yph = tf.placeholder('float', [None, neuronios_saida])\n",
        "\n",
        "modelo = mlp(xph, W, bias)\n",
        "erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits= modelo, labels= yph))\n",
        "otimizador = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(erro)\n",
        "\n",
        "# previsoes\n",
        "init = tf.global_variables_initializer()\n",
        "previsoes_teste = tf.nn.softmax(modelo)\n",
        "previsoes_corretas = tf.equal(tf.argmax(previsoes_teste, 1), tf.argmax(yph, 1))\n",
        "taxa_acerto = tf.reduce_mean(tf.cast(previsoes_corretas, tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  print('Treinamento')\n",
        "  for epoch in range(5000):\n",
        "    X_batch, y_batch = mnist.train.next_batch(128)\n",
        "    _, custo = sess.run([otimizador, erro], feed_dict={xph: X_batch, yph: y_batch})\n",
        "\n",
        "    if(epoch % 100 == 0):\n",
        "      acc = sess.run([taxa_acerto], feed_dict={xph: X_batch, yph: y_batch})\n",
        "      print(f'época {epoch} -> erro: {custo} | acc: {acc}')\n",
        "\n",
        "  print('\\nTaxa de acerto')\n",
        "  print(sess.run(taxa_acerto, feed_dict={xph: x_test, yph: y_test}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treinamento\n",
            "época 0 -> erro: 42425.0234375 | acc: [0.1015625]\n",
            "época 100 -> erro: 16108.0703125 | acc: [0.15625]\n",
            "época 200 -> erro: 8520.953125 | acc: [0.359375]\n",
            "época 300 -> erro: 6027.59912109375 | acc: [0.484375]\n",
            "época 400 -> erro: 4731.49365234375 | acc: [0.53125]\n",
            "época 500 -> erro: 3871.7705078125 | acc: [0.5703125]\n",
            "época 600 -> erro: 2808.26953125 | acc: [0.6953125]\n",
            "época 700 -> erro: 3230.0498046875 | acc: [0.65625]\n",
            "época 800 -> erro: 2981.89111328125 | acc: [0.71875]\n",
            "época 900 -> erro: 2234.716064453125 | acc: [0.7265625]\n",
            "época 1000 -> erro: 3274.86279296875 | acc: [0.6796875]\n",
            "época 1100 -> erro: 1869.9495849609375 | acc: [0.8125]\n",
            "época 1200 -> erro: 2225.98828125 | acc: [0.7734375]\n",
            "época 1300 -> erro: 2045.0531005859375 | acc: [0.7578125]\n",
            "época 1400 -> erro: 1663.361328125 | acc: [0.7890625]\n",
            "época 1500 -> erro: 1829.8822021484375 | acc: [0.796875]\n",
            "época 1600 -> erro: 1814.7877197265625 | acc: [0.7734375]\n",
            "época 1700 -> erro: 868.484130859375 | acc: [0.890625]\n",
            "época 1800 -> erro: 1382.1435546875 | acc: [0.828125]\n",
            "época 1900 -> erro: 1935.9296875 | acc: [0.765625]\n",
            "época 2000 -> erro: 1303.952880859375 | acc: [0.8671875]\n",
            "época 2100 -> erro: 969.8229370117188 | acc: [0.859375]\n",
            "época 2200 -> erro: 1171.003662109375 | acc: [0.7890625]\n",
            "época 2300 -> erro: 1367.5584716796875 | acc: [0.8671875]\n",
            "época 2400 -> erro: 754.3641357421875 | acc: [0.875]\n",
            "época 2500 -> erro: 1092.8023681640625 | acc: [0.875]\n",
            "época 2600 -> erro: 1852.346435546875 | acc: [0.8125]\n",
            "época 2700 -> erro: 963.640380859375 | acc: [0.828125]\n",
            "época 2800 -> erro: 1656.6468505859375 | acc: [0.8359375]\n",
            "época 2900 -> erro: 882.255615234375 | acc: [0.875]\n",
            "época 3000 -> erro: 861.749755859375 | acc: [0.8671875]\n",
            "época 3100 -> erro: 864.019287109375 | acc: [0.890625]\n",
            "época 3200 -> erro: 648.1383056640625 | acc: [0.921875]\n",
            "época 3300 -> erro: 1108.778076171875 | acc: [0.8984375]\n",
            "época 3400 -> erro: 1100.024658203125 | acc: [0.875]\n",
            "época 3500 -> erro: 1243.2357177734375 | acc: [0.828125]\n",
            "época 3600 -> erro: 737.573974609375 | acc: [0.875]\n",
            "época 3700 -> erro: 727.1513061523438 | acc: [0.875]\n",
            "época 3800 -> erro: 644.4435424804688 | acc: [0.890625]\n",
            "época 3900 -> erro: 789.7802124023438 | acc: [0.8671875]\n",
            "época 4000 -> erro: 758.0841064453125 | acc: [0.875]\n",
            "época 4100 -> erro: 478.3123779296875 | acc: [0.90625]\n",
            "época 4200 -> erro: 598.5165405273438 | acc: [0.921875]\n",
            "época 4300 -> erro: 636.9639892578125 | acc: [0.921875]\n",
            "época 4400 -> erro: 222.43882751464844 | acc: [0.953125]\n",
            "época 4500 -> erro: 650.786865234375 | acc: [0.90625]\n",
            "época 4600 -> erro: 781.2188720703125 | acc: [0.8984375]\n",
            "época 4700 -> erro: 953.651611328125 | acc: [0.8828125]\n",
            "época 4800 -> erro: 971.115966796875 | acc: [0.8125]\n",
            "época 4900 -> erro: 980.109619140625 | acc: [0.90625]\n",
            "\n",
            "Taxa de acerto\n",
            "0.8935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO3hevcQuJjq",
        "colab_type": "text"
      },
      "source": [
        "> # **Aula 019** - Classificação com Estimators - **Tensorflow: Redes Neurais - Classificação e Regressão**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L_lzMpauIum",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "8b23cfe1-8e8a-49d3-bb28-5eed84d3c130"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "base = pd.read_csv('census.csv')\n",
        "base.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>final-weight</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loos</th>\n",
              "      <th>hour-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age          workclass  final-weight  ... hour-per-week  native-country  income\n",
              "0   39          State-gov         77516  ...            40   United-States   <=50K\n",
              "1   50   Self-emp-not-inc         83311  ...            13   United-States   <=50K\n",
              "2   38            Private        215646  ...            40   United-States   <=50K\n",
              "3   53            Private        234721  ...            40   United-States   <=50K\n",
              "4   28            Private        338409  ...            40            Cuba   <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KyyH-Yqer1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b46d609-46ce-4ec3-ec3f-c79e2687fba4"
      },
      "source": [
        "base.income.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' <=50K', ' >50K'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMge7Y1meQU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1f1828c-7ecb-4165-9220-fc102c29b59f"
      },
      "source": [
        "def converte_classe(rotulo):\n",
        "  if(rotulo == ' <=50K'):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "base.income = base.income.apply(converte_classe)\n",
        "base.income.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKciSEcqfR7N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "3aa6ed38-ae82-4853-9775-bf65726467b0"
      },
      "source": [
        "X = base.drop('income', axis=1)\n",
        "y = base.income\n",
        "\n",
        "x_training, x_test, y_training, y_test = train_test_split(X, y, test_size=0.3)\n",
        "base.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'workclass', 'final-weight', 'education', 'education-num',\n",
              "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
              "       'capital-gain', 'capital-loos', 'hour-per-week', 'native-country',\n",
              "       'income'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FsAshFvf5Bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# colunas categoricas\n",
        "workclass      = tf.feature_column.categorical_column_with_hash_bucket(key = 'workclass', hash_bucket_size=100)\n",
        "education      = tf.feature_column.categorical_column_with_hash_bucket(key = 'education', hash_bucket_size=100)\n",
        "marital_status = tf.feature_column.categorical_column_with_hash_bucket(key = 'marital-status', hash_bucket_size=100)\n",
        "occupation     = tf.feature_column.categorical_column_with_hash_bucket(key = 'occupation', hash_bucket_size=100)\n",
        "relationship   = tf.feature_column.categorical_column_with_hash_bucket(key = 'relationship', hash_bucket_size=100)\n",
        "race           = tf.feature_column.categorical_column_with_hash_bucket(key = 'race', hash_bucket_size=100)\n",
        "sex            = tf.feature_column.categorical_column_with_vocabulary_list(key = 'sex', vocabulary_list=[' Male', ' Female'])\n",
        "native_country = tf.feature_column.categorical_column_with_hash_bucket(key = 'native-country', hash_bucket_size=100)\n",
        "\n",
        "# colunas numéricas\n",
        "age           = tf.feature_column.numeric_column(key = 'age')\n",
        "final_weight  = tf.feature_column.numeric_column(key = 'final-weight')\n",
        "capital_gain  = tf.feature_column.numeric_column(key = 'capital-gain')\n",
        "education_num = tf.feature_column.numeric_column(key = 'education-num')\n",
        "capital_loss  = tf.feature_column.numeric_column(key = 'capital-loos')\n",
        "hour          = tf.feature_column.numeric_column(key = 'hour-per-week')\n",
        "\n",
        "# colunas\n",
        "colunas = [age, workclass, final_weight, education, education_num,\n",
        "           marital_status, occupation, relationship, race, sex,\n",
        "           capital_gain, capital_loss, hour, native_country]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr5MrQ37lKEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedde_workclass = tf.feature_column.embedding_column(workclass, dimension=len(base.workclass.unique()))\n",
        "embedde_education = tf.feature_column.embedding_column(education, dimension=len(base.education.unique()))\n",
        "embedde_marital_status = tf.feature_column.embedding_column(marital_status, dimension=len(base['marital-status'].unique()))\n",
        "embedde_occupation = tf.feature_column.embedding_column(occupation, dimension=len(base.occupation.unique()))\n",
        "embedde_relationship = tf.feature_column.embedding_column(relationship, dimension=len(base.relationship.unique()))\n",
        "embedde_race = tf.feature_column.embedding_column(race, dimension=len(base.race.unique()))\n",
        "embedde_sex = tf.feature_column.embedding_column(sex, dimension=len(base.sex.unique()))\n",
        "embedde_native_country = tf.feature_column.embedding_column(native_country, dimension=len(base['native-country'].unique()))\n",
        "\n",
        "# colunas_rna\n",
        "colunas_rna = [age, embedde_workclass, final_weight, embedde_education, education_num,\n",
        "               embedde_marital_status, embedde_occupation, embedde_relationship, embedde_race, embedde_sex,\n",
        "               capital_gain, capital_loss, hour, embedde_native_country]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1h5rHvYjymB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a527176-1482-4a23-968b-2271ed9ce2f6"
      },
      "source": [
        "# funcoes\n",
        "training_function = tf.estimator.inputs.pandas_input_fn(x= x_training, y= y_training, batch_size= 32,\n",
        "                                                        num_epochs= None, shuffle= True)\n",
        "\n",
        "# hidden_units = lista de camadas ocultas, o número é a quantidade de neuronios da camada\n",
        "classificator = tf.estimator.DNNClassifier(hidden_units= [8, 8], feature_columns= colunas_rna, n_classes= 2)\n",
        "classificator.train(input_fn= training_function, steps= 10000)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp55ro4fsf\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp55ro4fsf', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4001597c50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp55ro4fsf/model.ckpt.\n",
            "INFO:tensorflow:loss = 236046.02, step = 1\n",
            "INFO:tensorflow:global_step/sec: 149.24\n",
            "INFO:tensorflow:loss = 19.565796, step = 101 (0.673 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 103 vs previous value: 103. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 166 vs previous value: 166. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 171 vs previous value: 171. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 228.862\n",
            "INFO:tensorflow:loss = 18.582354, step = 201 (0.436 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 206 vs previous value: 206. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 209 vs previous value: 209. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 224.07\n",
            "INFO:tensorflow:loss = 16.619564, step = 301 (0.446 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.54\n",
            "INFO:tensorflow:loss = 16.284779, step = 401 (0.431 sec)\n",
            "INFO:tensorflow:global_step/sec: 222.894\n",
            "INFO:tensorflow:loss = 19.995365, step = 501 (0.448 sec)\n",
            "INFO:tensorflow:global_step/sec: 226.658\n",
            "INFO:tensorflow:loss = 14.954119, step = 601 (0.439 sec)\n",
            "INFO:tensorflow:global_step/sec: 227.933\n",
            "INFO:tensorflow:loss = 19.037754, step = 701 (0.442 sec)\n",
            "INFO:tensorflow:global_step/sec: 225.665\n",
            "INFO:tensorflow:loss = 20.112854, step = 801 (0.451 sec)\n",
            "INFO:tensorflow:global_step/sec: 231.085\n",
            "INFO:tensorflow:loss = 16.909176, step = 901 (0.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 228.22\n",
            "INFO:tensorflow:loss = 14.687996, step = 1001 (0.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.666\n",
            "INFO:tensorflow:loss = 14.654589, step = 1101 (0.432 sec)\n",
            "INFO:tensorflow:global_step/sec: 229.475\n",
            "INFO:tensorflow:loss = 14.616892, step = 1201 (0.430 sec)\n",
            "INFO:tensorflow:global_step/sec: 231.084\n",
            "INFO:tensorflow:loss = 17.99702, step = 1301 (0.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 234.61\n",
            "INFO:tensorflow:loss = 16.878538, step = 1401 (0.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 222.513\n",
            "INFO:tensorflow:loss = 15.76152, step = 1501 (0.450 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.78\n",
            "INFO:tensorflow:loss = 15.747933, step = 1601 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 236.856\n",
            "INFO:tensorflow:loss = 17.998667, step = 1701 (0.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.522\n",
            "INFO:tensorflow:loss = 15.718709, step = 1801 (0.410 sec)\n",
            "INFO:tensorflow:global_step/sec: 238.786\n",
            "INFO:tensorflow:loss = 18.002686, step = 1901 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.462\n",
            "INFO:tensorflow:loss = 18.000797, step = 2001 (0.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.942\n",
            "INFO:tensorflow:loss = 22.528847, step = 2101 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 239.477\n",
            "INFO:tensorflow:loss = 13.484514, step = 2201 (0.418 sec)\n",
            "INFO:tensorflow:global_step/sec: 229.109\n",
            "INFO:tensorflow:loss = 20.265041, step = 2301 (0.436 sec)\n",
            "INFO:tensorflow:global_step/sec: 225.731\n",
            "INFO:tensorflow:loss = 18.000916, step = 2401 (0.451 sec)\n",
            "INFO:tensorflow:global_step/sec: 217.112\n",
            "INFO:tensorflow:loss = 16.85469, step = 2501 (0.452 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.754\n",
            "INFO:tensorflow:loss = 18.003733, step = 2601 (0.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 232.896\n",
            "INFO:tensorflow:loss = 15.7061, step = 2701 (0.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 232.607\n",
            "INFO:tensorflow:loss = 15.721735, step = 2801 (0.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 234.882\n",
            "INFO:tensorflow:loss = 16.865177, step = 2901 (0.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 229.293\n",
            "INFO:tensorflow:loss = 12.332504, step = 3001 (0.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.428\n",
            "INFO:tensorflow:loss = 15.716637, step = 3101 (0.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.186\n",
            "INFO:tensorflow:loss = 15.708484, step = 3201 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 234.429\n",
            "INFO:tensorflow:loss = 19.15857, step = 3301 (0.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 254.49\n",
            "INFO:tensorflow:loss = 22.609283, step = 3401 (0.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.829\n",
            "INFO:tensorflow:loss = 20.287811, step = 3501 (0.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 229.072\n",
            "INFO:tensorflow:loss = 15.735401, step = 3601 (0.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.955\n",
            "INFO:tensorflow:loss = 19.136208, step = 3701 (0.394 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.673\n",
            "INFO:tensorflow:loss = 18.000519, step = 3801 (0.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.533\n",
            "INFO:tensorflow:loss = 21.439945, step = 3901 (0.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 214.819\n",
            "INFO:tensorflow:loss = 19.154575, step = 4001 (0.464 sec)\n",
            "INFO:tensorflow:global_step/sec: 239.189\n",
            "INFO:tensorflow:loss = 15.705723, step = 4101 (0.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 224.622\n",
            "INFO:tensorflow:loss = 14.575265, step = 4201 (0.441 sec)\n",
            "INFO:tensorflow:global_step/sec: 226.678\n",
            "INFO:tensorflow:loss = 21.405716, step = 4301 (0.445 sec)\n",
            "INFO:tensorflow:global_step/sec: 230.904\n",
            "INFO:tensorflow:loss = 16.86052, step = 4401 (0.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 234.95\n",
            "INFO:tensorflow:loss = 21.436745, step = 4501 (0.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 227.22\n",
            "INFO:tensorflow:loss = 16.856617, step = 4601 (0.444 sec)\n",
            "INFO:tensorflow:global_step/sec: 229.604\n",
            "INFO:tensorflow:loss = 19.15298, step = 4701 (0.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.523\n",
            "INFO:tensorflow:loss = 15.708486, step = 4801 (0.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 234.723\n",
            "INFO:tensorflow:loss = 20.286928, step = 4901 (0.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 235.419\n",
            "INFO:tensorflow:loss = 20.267225, step = 5001 (0.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 228.966\n",
            "INFO:tensorflow:loss = 23.689753, step = 5101 (0.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 234.846\n",
            "INFO:tensorflow:loss = 20.285896, step = 5201 (0.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 234.133\n",
            "INFO:tensorflow:loss = 18.001505, step = 5301 (0.432 sec)\n",
            "INFO:tensorflow:global_step/sec: 215.967\n",
            "INFO:tensorflow:loss = 21.456688, step = 5401 (0.459 sec)\n",
            "INFO:tensorflow:global_step/sec: 235.946\n",
            "INFO:tensorflow:loss = 19.151573, step = 5501 (0.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 223.477\n",
            "INFO:tensorflow:loss = 15.713997, step = 5601 (0.446 sec)\n",
            "INFO:tensorflow:global_step/sec: 223.122\n",
            "INFO:tensorflow:loss = 16.864353, step = 5701 (0.454 sec)\n",
            "INFO:tensorflow:global_step/sec: 228.01\n",
            "INFO:tensorflow:loss = 15.729307, step = 5801 (0.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.204\n",
            "INFO:tensorflow:loss = 16.858332, step = 5901 (0.431 sec)\n",
            "INFO:tensorflow:global_step/sec: 221.989\n",
            "INFO:tensorflow:loss = 15.715656, step = 6001 (0.457 sec)\n",
            "INFO:tensorflow:global_step/sec: 231.106\n",
            "INFO:tensorflow:loss = 18.001514, step = 6101 (0.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 234.69\n",
            "INFO:tensorflow:loss = 18.002357, step = 6201 (0.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 227.203\n",
            "INFO:tensorflow:loss = 13.41283, step = 6301 (0.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 220.861\n",
            "INFO:tensorflow:loss = 21.418945, step = 6401 (0.453 sec)\n",
            "INFO:tensorflow:global_step/sec: 229.281\n",
            "INFO:tensorflow:loss = 15.724255, step = 6501 (0.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.883\n",
            "INFO:tensorflow:loss = 18.00086, step = 6601 (0.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 228.144\n",
            "INFO:tensorflow:loss = 22.582474, step = 6701 (0.438 sec)\n",
            "INFO:tensorflow:global_step/sec: 225.618\n",
            "INFO:tensorflow:loss = 19.148548, step = 6801 (0.445 sec)\n",
            "INFO:tensorflow:global_step/sec: 226.327\n",
            "INFO:tensorflow:loss = 15.701942, step = 6901 (0.442 sec)\n",
            "INFO:tensorflow:global_step/sec: 225.544\n",
            "INFO:tensorflow:loss = 16.855198, step = 7001 (0.444 sec)\n",
            "INFO:tensorflow:global_step/sec: 232.041\n",
            "INFO:tensorflow:loss = 22.544868, step = 7101 (0.433 sec)\n",
            "INFO:tensorflow:global_step/sec: 237.046\n",
            "INFO:tensorflow:loss = 16.862555, step = 7201 (0.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 226.545\n",
            "INFO:tensorflow:loss = 14.582817, step = 7301 (0.444 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.224\n",
            "INFO:tensorflow:loss = 15.714776, step = 7401 (0.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 227.422\n",
            "INFO:tensorflow:loss = 14.562566, step = 7501 (0.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 225.881\n",
            "INFO:tensorflow:loss = 16.852562, step = 7601 (0.449 sec)\n",
            "INFO:tensorflow:global_step/sec: 222.61\n",
            "INFO:tensorflow:loss = 18.001362, step = 7701 (0.441 sec)\n",
            "INFO:tensorflow:global_step/sec: 226.747\n",
            "INFO:tensorflow:loss = 16.859087, step = 7801 (0.441 sec)\n",
            "INFO:tensorflow:global_step/sec: 225.085\n",
            "INFO:tensorflow:loss = 14.591471, step = 7901 (0.446 sec)\n",
            "INFO:tensorflow:global_step/sec: 224.981\n",
            "INFO:tensorflow:loss = 16.861504, step = 8001 (0.449 sec)\n",
            "INFO:tensorflow:global_step/sec: 227.509\n",
            "INFO:tensorflow:loss = 15.711378, step = 8101 (0.441 sec)\n",
            "INFO:tensorflow:global_step/sec: 228.602\n",
            "INFO:tensorflow:loss = 13.408838, step = 8201 (0.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 231.882\n",
            "INFO:tensorflow:loss = 16.852154, step = 8301 (0.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 229.673\n",
            "INFO:tensorflow:loss = 15.708569, step = 8401 (0.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 226.787\n",
            "INFO:tensorflow:loss = 18.000599, step = 8501 (0.442 sec)\n",
            "INFO:tensorflow:global_step/sec: 223.555\n",
            "INFO:tensorflow:loss = 15.724646, step = 8601 (0.444 sec)\n",
            "INFO:tensorflow:global_step/sec: 221.234\n",
            "INFO:tensorflow:loss = 16.861311, step = 8701 (0.452 sec)\n",
            "INFO:tensorflow:global_step/sec: 229.361\n",
            "INFO:tensorflow:loss = 14.572163, step = 8801 (0.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 216.292\n",
            "INFO:tensorflow:loss = 14.559987, step = 8901 (0.462 sec)\n",
            "INFO:tensorflow:global_step/sec: 226.425\n",
            "INFO:tensorflow:loss = 21.453564, step = 9001 (0.447 sec)\n",
            "INFO:tensorflow:global_step/sec: 225.818\n",
            "INFO:tensorflow:loss = 20.29736, step = 9101 (0.437 sec)\n",
            "INFO:tensorflow:global_step/sec: 232.805\n",
            "INFO:tensorflow:loss = 19.144041, step = 9201 (0.430 sec)\n",
            "INFO:tensorflow:global_step/sec: 231.339\n",
            "INFO:tensorflow:loss = 13.454214, step = 9301 (0.437 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.595\n",
            "INFO:tensorflow:loss = 19.13997, step = 9401 (0.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 224.238\n",
            "INFO:tensorflow:loss = 22.567135, step = 9501 (0.453 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.4\n",
            "INFO:tensorflow:loss = 16.854511, step = 9601 (0.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 257.61\n",
            "INFO:tensorflow:loss = 15.703484, step = 9701 (0.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 221.509\n",
            "INFO:tensorflow:loss = 21.447931, step = 9801 (0.451 sec)\n",
            "INFO:tensorflow:global_step/sec: 228.218\n",
            "INFO:tensorflow:loss = 20.286709, step = 9901 (0.437 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmp55ro4fsf/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 16.862896.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f40015973c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBywyVXsoCaE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "e51ff74e-5207-4c37-a1d1-f58315df896f"
      },
      "source": [
        "# testes\n",
        "test_function = tf.estimator.inputs.pandas_input_fn(x= x_test, y= y_test, batch_size= 32,\n",
        "                                                    num_epochs= 1, shuffle= False)\n",
        "classificator.evaluate(input_fn= test_function)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-02-17T14:51:28Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp55ro4fsf/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-02-17-14:51:30\n",
            "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.7612857, accuracy_baseline = 0.7612857, auc = 0.5, auc_precision_recall = 0.8806429, average_loss = 0.5496445, global_step = 10000, label/mean = 0.7612857, loss = 17.54731, precision = 0.7612857, prediction/mean = 0.756973, recall = 1.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/tmp55ro4fsf/model.ckpt-10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7612857,\n",
              " 'accuracy_baseline': 0.7612857,\n",
              " 'auc': 0.5,\n",
              " 'auc_precision_recall': 0.8806429,\n",
              " 'average_loss': 0.5496445,\n",
              " 'global_step': 10000,\n",
              " 'label/mean': 0.7612857,\n",
              " 'loss': 17.54731,\n",
              " 'precision': 0.7612857,\n",
              " 'prediction/mean': 0.756973,\n",
              " 'recall': 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--9Vb6c_ovSL",
        "colab_type": "text"
      },
      "source": [
        "> # **Aula 020** - Padronização com TensorFlow - **Tensorflow: Redes Neurais - Classificação e Regressão**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6zgEn_YouFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "f339a7e6-6522-4361-a07c-b64f2666fd33"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "base = pd.read_csv('census.csv')\n",
        "base.head()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>final-weight</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loos</th>\n",
              "      <th>hour-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age          workclass  final-weight  ... hour-per-week  native-country  income\n",
              "0   39          State-gov         77516  ...            40   United-States   <=50K\n",
              "1   50   Self-emp-not-inc         83311  ...            13   United-States   <=50K\n",
              "2   38            Private        215646  ...            40   United-States   <=50K\n",
              "3   53            Private        234721  ...            40   United-States   <=50K\n",
              "4   28            Private        338409  ...            40            Cuba   <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohpaWrvpRKn",
        "colab_type": "text"
      },
      "source": [
        "# Normalização **(máximo(x) e mínimo(x) onde x é da base vai ser normalizada)**\n",
        "> *x = (x - mínimo(x)) / (máximo(x) - mínimo(x))*\n",
        "\n",
        "# Padronização **(média(x) é a média de todos valores da base que vai ser padronizada e desvio_padrão(x) é quanto o x desvia da média para cima ou para baixo)**\n",
        "> *x = (x - média(x) / desvio_padrão(x))*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkFMHGWpL61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75ba9f13-a77c-4bde-bf09-9be61f147b75"
      },
      "source": [
        "base.age.mean() # média"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38.58164675532078"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tlmKKdUrnCx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee553d90-e93e-4bae-82d3-b0c563d500f2"
      },
      "source": [
        "base.age.std() # desvio_padrão"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.640432553581146"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLRBFwRwryb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padroniza_age(valor):\n",
        "  mean = base.age.mean()\n",
        "  std = base.age.std()\n",
        "  return tf.divide(tf.subtract( tf.cast(valor, tf.float32), tf.constant(mean)), tf.constant(std))\n",
        "\n",
        "def padroniza_final_weight(valor):\n",
        "  mean = base['final-weight'].mean()\n",
        "  std = base['final-weight'].std()\n",
        "  return tf.divide(tf.subtract( tf.cast(valor, tf.float32), tf.constant(mean)), tf.constant(std))\n",
        "\n",
        "def padroniza_capital_gain(valor):\n",
        "  mean = base['capital-gain'].mean()\n",
        "  std = base['capital-gain'].std()\n",
        "  return tf.divide(tf.subtract( tf.cast(valor, tf.float32), tf.constant(mean)), tf.constant(std))\n",
        "\n",
        "def padroniza_education_num(valor):\n",
        "  mean = base['education-num'].mean()\n",
        "  std = base['education-num'].std()\n",
        "  return tf.divide(tf.subtract( tf.cast(valor, tf.float32), tf.constant(mean)), tf.constant(std))\n",
        "\n",
        "def padroniza_capital_loos(valor):\n",
        "  mean = base['capital-loos'].mean()\n",
        "  std = base['capital-loos'].std()\n",
        "  return tf.divide(tf.subtract( tf.cast(valor, tf.float32), tf.constant(mean)), tf.constant(std))\n",
        "\n",
        "def padroniza_hour(valor):\n",
        "  mean = base.hour.mean()\n",
        "  std = base.hour.std()\n",
        "  return tf.divide(tf.subtract( tf.cast(valor, tf.float32), tf.constant(mean)), tf.constant(std))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lh-mbe7rgg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# colunas numéricas\n",
        "age           = tf.feature_column.numeric_column(key = 'age', normalizer_fn=padroniza_age)\n",
        "final_weight  = tf.feature_column.numeric_column(key = 'final-weight', normalizer_fn=padroniza_final_weight)\n",
        "capital_gain  = tf.feature_column.numeric_column(key = 'capital-gain', normalizer_fn=padroniza_capital_gain)\n",
        "education_num = tf.feature_column.numeric_column(key = 'education-num', normalizer_fn=padroniza_education_num)\n",
        "capital_loos  = tf.feature_column.numeric_column(key = 'capital-loos', normalizer_fn=padroniza_capital_loos)\n",
        "hour          = tf.feature_column.numeric_column(key = 'hour-per-week', normalizer_fn=padroniza_hour)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqwIysD6uZMj",
        "colab_type": "text"
      },
      "source": [
        "> # **Aula 021** - Regressão com Estimators - **Tensorflow: Redes Neurais - Classificação e Regressão**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFWej1QquWan",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "6d9f80d0-31d5-40fd-8562-8561b1c5ac1f"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "base = pd.read_csv('house-prices.csv')\n",
        "base.head()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.019266</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.067170</td>\n",
              "      <td>0.003108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.097588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.893939</td>\n",
              "      <td>0.571498</td>\n",
              "      <td>0.217608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.060721</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.28125</td>\n",
              "      <td>0.172075</td>\n",
              "      <td>0.004072</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.206140</td>\n",
              "      <td>0.082988</td>\n",
              "      <td>0.443478</td>\n",
              "      <td>0.988089</td>\n",
              "      <td>0.626263</td>\n",
              "      <td>0.908959</td>\n",
              "      <td>0.166113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.013770</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.036226</td>\n",
              "      <td>0.005743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.286957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.936143</td>\n",
              "      <td>0.237542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.069377</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.126038</td>\n",
              "      <td>0.002714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.188797</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.586939</td>\n",
              "      <td>0.104651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.057049</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.25000</td>\n",
              "      <td>0.104906</td>\n",
              "      <td>0.004579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.152412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.368687</td>\n",
              "      <td>0.741354</td>\n",
              "      <td>0.393688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  bedrooms  bathrooms  ...   zipcode       lat      long\n",
              "0  0.019266  0.090909    0.12500  ...  0.893939  0.571498  0.217608\n",
              "1  0.060721  0.090909    0.28125  ...  0.626263  0.908959  0.166113\n",
              "2  0.013770  0.060606    0.12500  ...  0.136364  0.936143  0.237542\n",
              "3  0.069377  0.121212    0.37500  ...  0.681818  0.586939  0.104651\n",
              "4  0.057049  0.090909    0.25000  ...  0.368687  0.741354  0.393688\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZZctY0euv2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "c4f35f8a-66ae-46c2-ea5c-a3eb31a4bd98"
      },
      "source": [
        "base.columns"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
              "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
              "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
              "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxZq3v4fuyEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "2f34c74e-6401-43d4-cc7d-0331ceed2b40"
      },
      "source": [
        "colunas_usadas = ['price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
        "                  'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
        "                  'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
        "                  'lat', 'long']\n",
        "base = pd.read_csv('house-prices.csv', usecols= colunas_usadas)\n",
        "base.head()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  bedrooms  bathrooms  ...  zipcode      lat     long\n",
              "0  221900.0         3       1.00  ...    98178  47.5112 -122.257\n",
              "1  538000.0         3       2.25  ...    98125  47.7210 -122.319\n",
              "2  180000.0         2       1.00  ...    98028  47.7379 -122.233\n",
              "3  604000.0         4       3.00  ...    98136  47.5208 -122.393\n",
              "4  510000.0         3       2.00  ...    98074  47.6168 -122.045\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnT8WVYqvUFg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "c3df8597-ec23-4a24-d7c9-3c837b30a1a5"
      },
      "source": [
        "# normalizando os dados\n",
        "scaler_attrs = MinMaxScaler()\n",
        "\n",
        "base[['bedrooms', 'bathrooms', 'sqft_living',\n",
        "      'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
        "      'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
        "      'lat', 'long']] = scaler_attrs.fit_transform(base[['bedrooms', 'bathrooms', 'sqft_living',\n",
        "                                                    'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
        "                                                    'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
        "                                                    'lat', 'long']])\n",
        "base.head()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>221900.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.067170</td>\n",
              "      <td>0.003108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.097588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.893939</td>\n",
              "      <td>0.571498</td>\n",
              "      <td>0.217608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>538000.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.28125</td>\n",
              "      <td>0.172075</td>\n",
              "      <td>0.004072</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.206140</td>\n",
              "      <td>0.082988</td>\n",
              "      <td>0.443478</td>\n",
              "      <td>0.988089</td>\n",
              "      <td>0.626263</td>\n",
              "      <td>0.908959</td>\n",
              "      <td>0.166113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180000.0</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.036226</td>\n",
              "      <td>0.005743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.286957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.936143</td>\n",
              "      <td>0.237542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>604000.0</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.126038</td>\n",
              "      <td>0.002714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.188797</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.586939</td>\n",
              "      <td>0.104651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>510000.0</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.25000</td>\n",
              "      <td>0.104906</td>\n",
              "      <td>0.004579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.152412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.368687</td>\n",
              "      <td>0.741354</td>\n",
              "      <td>0.393688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  bedrooms  bathrooms  ...   zipcode       lat      long\n",
              "0  221900.0  0.090909    0.12500  ...  0.893939  0.571498  0.217608\n",
              "1  538000.0  0.090909    0.28125  ...  0.626263  0.908959  0.166113\n",
              "2  180000.0  0.060606    0.12500  ...  0.136364  0.936143  0.237542\n",
              "3  604000.0  0.121212    0.37500  ...  0.681818  0.586939  0.104651\n",
              "4  510000.0  0.090909    0.25000  ...  0.368687  0.741354  0.393688\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAoDPUIHv0tx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "d2be284e-db24-4788-ad0c-1abb52ae3f91"
      },
      "source": [
        "scaler_preco = MinMaxScaler()\n",
        "base[['price']] = scaler_preco.fit_transform(base[['price']])\n",
        "base.head()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.019266</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.067170</td>\n",
              "      <td>0.003108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.097588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.893939</td>\n",
              "      <td>0.571498</td>\n",
              "      <td>0.217608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.060721</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.28125</td>\n",
              "      <td>0.172075</td>\n",
              "      <td>0.004072</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.206140</td>\n",
              "      <td>0.082988</td>\n",
              "      <td>0.443478</td>\n",
              "      <td>0.988089</td>\n",
              "      <td>0.626263</td>\n",
              "      <td>0.908959</td>\n",
              "      <td>0.166113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.013770</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.036226</td>\n",
              "      <td>0.005743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.286957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.936143</td>\n",
              "      <td>0.237542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.069377</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.126038</td>\n",
              "      <td>0.002714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.188797</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.586939</td>\n",
              "      <td>0.104651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.057049</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.25000</td>\n",
              "      <td>0.104906</td>\n",
              "      <td>0.004579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.152412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.368687</td>\n",
              "      <td>0.741354</td>\n",
              "      <td>0.393688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  bedrooms  bathrooms  ...   zipcode       lat      long\n",
              "0  0.019266  0.090909    0.12500  ...  0.893939  0.571498  0.217608\n",
              "1  0.060721  0.090909    0.28125  ...  0.626263  0.908959  0.166113\n",
              "2  0.013770  0.060606    0.12500  ...  0.136364  0.936143  0.237542\n",
              "3  0.069377  0.121212    0.37500  ...  0.681818  0.586939  0.104651\n",
              "4  0.057049  0.090909    0.25000  ...  0.368687  0.741354  0.393688\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEWE1bQTv-PJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "395c6031-44e9-470f-db99-8b1cb723b921"
      },
      "source": [
        "X = base.drop('price', axis=1)\n",
        "y = base.price\n",
        "\n",
        "colunas_previsoras = colunas_usadas[1:17]\n",
        "colunas = [tf.feature_column.numeric_column(key = c) for c in colunas_previsoras]\n",
        "\n",
        "x_training, x_test, y_training, y_test = train_test_split(X, y, test_size= 0.3)\n",
        "\n",
        "training_function = tf.estimator.inputs.pandas_input_fn(x= x_training, y= y_training, batch_size= 32,\n",
        "                                                        num_epochs= None, shuffle= True)\n",
        "regressor = tf.estimator.DNNRegressor(hidden_units=[8,8,8], feature_columns= colunas)\n",
        "regressor.train(input_fn=training_function, steps= 20000)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpv1dtw8fu\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpv1dtw8fu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4000afd4a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpv1dtw8fu/model.ckpt.\n",
            "INFO:tensorflow:loss = 12.076843, step = 1\n",
            "INFO:tensorflow:global_step/sec: 278.012\n",
            "INFO:tensorflow:loss = 0.032589108, step = 101 (0.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 291.644\n",
            "INFO:tensorflow:loss = 0.12726982, step = 201 (0.337 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.859\n",
            "INFO:tensorflow:loss = 0.028489621, step = 301 (0.354 sec)\n",
            "INFO:tensorflow:global_step/sec: 276.467\n",
            "INFO:tensorflow:loss = 0.019503659, step = 401 (0.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 273.051\n",
            "INFO:tensorflow:loss = 0.019417241, step = 501 (0.370 sec)\n",
            "INFO:tensorflow:global_step/sec: 274.131\n",
            "INFO:tensorflow:loss = 0.010455083, step = 601 (0.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 274.141\n",
            "INFO:tensorflow:loss = 0.016563037, step = 701 (0.365 sec)\n",
            "INFO:tensorflow:global_step/sec: 273.82\n",
            "INFO:tensorflow:loss = 0.014360238, step = 801 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.571\n",
            "INFO:tensorflow:loss = 0.024888054, step = 901 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.423\n",
            "INFO:tensorflow:loss = 0.041886143, step = 1001 (0.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.32\n",
            "INFO:tensorflow:loss = 0.023985408, step = 1101 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 195.899\n",
            "INFO:tensorflow:loss = 0.033559848, step = 1201 (0.510 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.819\n",
            "INFO:tensorflow:loss = 0.03311792, step = 1301 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.702\n",
            "INFO:tensorflow:loss = 0.0629495, step = 1401 (0.386 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.628\n",
            "INFO:tensorflow:loss = 0.010609327, step = 1501 (0.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 278.113\n",
            "INFO:tensorflow:loss = 0.023856733, step = 1601 (0.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 270.115\n",
            "INFO:tensorflow:loss = 0.030737042, step = 1701 (0.372 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.151\n",
            "INFO:tensorflow:loss = 0.008999789, step = 1801 (0.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.419\n",
            "INFO:tensorflow:loss = 0.009677686, step = 1901 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.205\n",
            "INFO:tensorflow:loss = 0.044525664, step = 2001 (0.365 sec)\n",
            "INFO:tensorflow:global_step/sec: 266.313\n",
            "INFO:tensorflow:loss = 0.020045586, step = 2101 (0.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 273.76\n",
            "INFO:tensorflow:loss = 0.02061455, step = 2201 (0.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 268.823\n",
            "INFO:tensorflow:loss = 0.03306856, step = 2301 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.44\n",
            "INFO:tensorflow:loss = 0.012709942, step = 2401 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 272.267\n",
            "INFO:tensorflow:loss = 0.027292531, step = 2501 (0.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.07\n",
            "INFO:tensorflow:loss = 0.030661067, step = 2601 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.422\n",
            "INFO:tensorflow:loss = 0.014514179, step = 2701 (0.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.099\n",
            "INFO:tensorflow:loss = 0.010006124, step = 2801 (0.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 276.28\n",
            "INFO:tensorflow:loss = 0.04034956, step = 2901 (0.365 sec)\n",
            "INFO:tensorflow:global_step/sec: 267.73\n",
            "INFO:tensorflow:loss = 0.0058237724, step = 3001 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 273.351\n",
            "INFO:tensorflow:loss = 0.020005468, step = 3101 (0.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 261.457\n",
            "INFO:tensorflow:loss = 0.01346237, step = 3201 (0.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 276.032\n",
            "INFO:tensorflow:loss = 0.042225722, step = 3301 (0.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.956\n",
            "INFO:tensorflow:loss = 0.017789569, step = 3401 (0.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 276.867\n",
            "INFO:tensorflow:loss = 0.0069779754, step = 3501 (0.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 263.829\n",
            "INFO:tensorflow:loss = 0.012683164, step = 3601 (0.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 263.421\n",
            "INFO:tensorflow:loss = 0.023004258, step = 3701 (0.372 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.16\n",
            "INFO:tensorflow:loss = 0.030385612, step = 3801 (0.354 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.443\n",
            "INFO:tensorflow:loss = 0.012456801, step = 3901 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.678\n",
            "INFO:tensorflow:loss = 0.024271123, step = 4001 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.973\n",
            "INFO:tensorflow:loss = 0.020481804, step = 4101 (0.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 283.877\n",
            "INFO:tensorflow:loss = 0.009109417, step = 4201 (0.352 sec)\n",
            "INFO:tensorflow:global_step/sec: 261.936\n",
            "INFO:tensorflow:loss = 0.06977573, step = 4301 (0.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 270.313\n",
            "INFO:tensorflow:loss = 0.0509065, step = 4401 (0.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.891\n",
            "INFO:tensorflow:loss = 0.010318336, step = 4501 (0.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 257.029\n",
            "INFO:tensorflow:loss = 0.014405264, step = 4601 (0.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.027\n",
            "INFO:tensorflow:loss = 0.013229019, step = 4701 (0.370 sec)\n",
            "INFO:tensorflow:global_step/sec: 268.465\n",
            "INFO:tensorflow:loss = 0.009224212, step = 4801 (0.372 sec)\n",
            "INFO:tensorflow:global_step/sec: 276.483\n",
            "INFO:tensorflow:loss = 0.017137725, step = 4901 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.849\n",
            "INFO:tensorflow:loss = 0.025984026, step = 5001 (0.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 277.546\n",
            "INFO:tensorflow:loss = 0.014594222, step = 5101 (0.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 282.897\n",
            "INFO:tensorflow:loss = 0.040977478, step = 5201 (0.354 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.121\n",
            "INFO:tensorflow:loss = 0.011501836, step = 5301 (0.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.595\n",
            "INFO:tensorflow:loss = 0.016366854, step = 5401 (0.359 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.851\n",
            "INFO:tensorflow:loss = 0.018164426, step = 5501 (0.354 sec)\n",
            "INFO:tensorflow:global_step/sec: 283.992\n",
            "INFO:tensorflow:loss = 0.009225946, step = 5601 (0.353 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.087\n",
            "INFO:tensorflow:loss = 0.019826084, step = 5701 (0.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 297.034\n",
            "INFO:tensorflow:loss = 0.0052156434, step = 5801 (0.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.641\n",
            "INFO:tensorflow:loss = 0.010228829, step = 5901 (0.345 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.087\n",
            "INFO:tensorflow:loss = 0.019861396, step = 6001 (0.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 276.161\n",
            "INFO:tensorflow:loss = 0.013064068, step = 6101 (0.359 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.069\n",
            "INFO:tensorflow:loss = 0.012621086, step = 6201 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 289.468\n",
            "INFO:tensorflow:loss = 0.022356935, step = 6301 (0.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 290.569\n",
            "INFO:tensorflow:loss = 0.010274311, step = 6401 (0.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 288.88\n",
            "INFO:tensorflow:loss = 0.012576165, step = 6501 (0.345 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.34\n",
            "INFO:tensorflow:loss = 0.013575361, step = 6601 (0.337 sec)\n",
            "INFO:tensorflow:global_step/sec: 292.045\n",
            "INFO:tensorflow:loss = 0.017633962, step = 6701 (0.349 sec)\n",
            "INFO:tensorflow:global_step/sec: 291.801\n",
            "INFO:tensorflow:loss = 0.02725511, step = 6801 (0.336 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.001\n",
            "INFO:tensorflow:loss = 0.01306077, step = 6901 (0.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.327\n",
            "INFO:tensorflow:loss = 0.017274357, step = 7001 (0.348 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.93\n",
            "INFO:tensorflow:loss = 0.00866434, step = 7101 (0.332 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.416\n",
            "INFO:tensorflow:loss = 0.034089096, step = 7201 (0.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.932\n",
            "INFO:tensorflow:loss = 0.017817674, step = 7301 (0.352 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.29\n",
            "INFO:tensorflow:loss = 0.0137358485, step = 7401 (0.346 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.919\n",
            "INFO:tensorflow:loss = 0.009780411, step = 7501 (0.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 265.759\n",
            "INFO:tensorflow:loss = 0.013775354, step = 7601 (0.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.957\n",
            "INFO:tensorflow:loss = 0.00846535, step = 7701 (0.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.535\n",
            "INFO:tensorflow:loss = 0.021711327, step = 7801 (0.352 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.478\n",
            "INFO:tensorflow:loss = 0.028967008, step = 7901 (0.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 266.861\n",
            "INFO:tensorflow:loss = 0.0075695273, step = 8001 (0.373 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.287\n",
            "INFO:tensorflow:loss = 0.016068356, step = 8101 (0.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 286.425\n",
            "INFO:tensorflow:loss = 0.02764322, step = 8201 (0.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.895\n",
            "INFO:tensorflow:loss = 0.011688052, step = 8301 (0.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.448\n",
            "INFO:tensorflow:loss = 0.015136671, step = 8401 (0.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.722\n",
            "INFO:tensorflow:loss = 0.010776163, step = 8501 (0.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 272.928\n",
            "INFO:tensorflow:loss = 0.03352865, step = 8601 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.616\n",
            "INFO:tensorflow:loss = 0.010230056, step = 8701 (0.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.669\n",
            "INFO:tensorflow:loss = 0.021593207, step = 8801 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 301.467\n",
            "INFO:tensorflow:loss = 0.0153924525, step = 8901 (0.332 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.231\n",
            "INFO:tensorflow:loss = 0.026990267, step = 9001 (0.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 283.553\n",
            "INFO:tensorflow:loss = 0.0150835235, step = 9101 (0.353 sec)\n",
            "INFO:tensorflow:global_step/sec: 288.447\n",
            "INFO:tensorflow:loss = 0.020752823, step = 9201 (0.349 sec)\n",
            "INFO:tensorflow:global_step/sec: 278.158\n",
            "INFO:tensorflow:loss = 0.0071012196, step = 9301 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.218\n",
            "INFO:tensorflow:loss = 0.009784631, step = 9401 (0.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.88\n",
            "INFO:tensorflow:loss = 0.005620526, step = 9501 (0.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.53\n",
            "INFO:tensorflow:loss = 0.051117867, step = 9601 (0.344 sec)\n",
            "INFO:tensorflow:global_step/sec: 289.631\n",
            "INFO:tensorflow:loss = 0.034601074, step = 9701 (0.345 sec)\n",
            "INFO:tensorflow:global_step/sec: 295.805\n",
            "INFO:tensorflow:loss = 0.034187905, step = 9801 (0.337 sec)\n",
            "INFO:tensorflow:global_step/sec: 299.647\n",
            "INFO:tensorflow:loss = 0.0073171104, step = 9901 (0.335 sec)\n",
            "INFO:tensorflow:global_step/sec: 302.695\n",
            "INFO:tensorflow:loss = 0.014808243, step = 10001 (0.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.111\n",
            "INFO:tensorflow:loss = 0.011619089, step = 10101 (0.334 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.611\n",
            "INFO:tensorflow:loss = 0.014233434, step = 10201 (0.346 sec)\n",
            "INFO:tensorflow:global_step/sec: 289.687\n",
            "INFO:tensorflow:loss = 0.008161293, step = 10301 (0.345 sec)\n",
            "INFO:tensorflow:global_step/sec: 286.785\n",
            "INFO:tensorflow:loss = 0.039477512, step = 10401 (0.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 277.48\n",
            "INFO:tensorflow:loss = 0.0053647407, step = 10501 (0.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 288.591\n",
            "INFO:tensorflow:loss = 0.046633057, step = 10601 (0.347 sec)\n",
            "INFO:tensorflow:global_step/sec: 263.769\n",
            "INFO:tensorflow:loss = 0.019233886, step = 10701 (0.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.353\n",
            "INFO:tensorflow:loss = 0.013969254, step = 10801 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.389\n",
            "INFO:tensorflow:loss = 0.009876269, step = 10901 (0.349 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.292\n",
            "INFO:tensorflow:loss = 0.016438605, step = 11001 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.687\n",
            "INFO:tensorflow:loss = 0.008533508, step = 11101 (0.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 288.988\n",
            "INFO:tensorflow:loss = 0.017841391, step = 11201 (0.339 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.558\n",
            "INFO:tensorflow:loss = 0.014413238, step = 11301 (0.349 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.32\n",
            "INFO:tensorflow:loss = 0.008270563, step = 11401 (0.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.287\n",
            "INFO:tensorflow:loss = 0.019158224, step = 11501 (0.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 268.889\n",
            "INFO:tensorflow:loss = 0.017137866, step = 11601 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 266.388\n",
            "INFO:tensorflow:loss = 0.023104914, step = 11701 (0.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 291.319\n",
            "INFO:tensorflow:loss = 0.0073721325, step = 11801 (0.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.959\n",
            "INFO:tensorflow:loss = 0.0259974, step = 11901 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 288.841\n",
            "INFO:tensorflow:loss = 0.013138367, step = 12001 (0.345 sec)\n",
            "INFO:tensorflow:global_step/sec: 283.756\n",
            "INFO:tensorflow:loss = 0.027955309, step = 12101 (0.352 sec)\n",
            "INFO:tensorflow:global_step/sec: 267.266\n",
            "INFO:tensorflow:loss = 0.008683974, step = 12201 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.324\n",
            "INFO:tensorflow:loss = 0.012979033, step = 12301 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.537\n",
            "INFO:tensorflow:loss = 0.013906812, step = 12401 (0.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.769\n",
            "INFO:tensorflow:loss = 0.011657539, step = 12501 (0.346 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.806\n",
            "INFO:tensorflow:loss = 0.011172205, step = 12601 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.607\n",
            "INFO:tensorflow:loss = 0.018035375, step = 12701 (0.352 sec)\n",
            "INFO:tensorflow:global_step/sec: 306.431\n",
            "INFO:tensorflow:loss = 0.028579928, step = 12801 (0.325 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.511\n",
            "INFO:tensorflow:loss = 0.0155684445, step = 12901 (0.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 277.842\n",
            "INFO:tensorflow:loss = 0.009070491, step = 13001 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 289.252\n",
            "INFO:tensorflow:loss = 0.016883463, step = 13101 (0.344 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.294\n",
            "INFO:tensorflow:loss = 0.010491364, step = 13201 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 291.022\n",
            "INFO:tensorflow:loss = 0.015332296, step = 13301 (0.344 sec)\n",
            "INFO:tensorflow:global_step/sec: 278.786\n",
            "INFO:tensorflow:loss = 0.015842304, step = 13401 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.248\n",
            "INFO:tensorflow:loss = 0.012756944, step = 13501 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 251.402\n",
            "INFO:tensorflow:loss = 0.028126586, step = 13601 (0.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 290.278\n",
            "INFO:tensorflow:loss = 0.008707563, step = 13701 (0.346 sec)\n",
            "INFO:tensorflow:global_step/sec: 276.932\n",
            "INFO:tensorflow:loss = 0.028377533, step = 13801 (0.362 sec)\n",
            "INFO:tensorflow:global_step/sec: 277.012\n",
            "INFO:tensorflow:loss = 0.010811437, step = 13901 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.114\n",
            "INFO:tensorflow:loss = 0.018544452, step = 14001 (0.346 sec)\n",
            "INFO:tensorflow:global_step/sec: 289.708\n",
            "INFO:tensorflow:loss = 0.024199385, step = 14101 (0.354 sec)\n",
            "INFO:tensorflow:global_step/sec: 288.991\n",
            "INFO:tensorflow:loss = 0.014833663, step = 14201 (0.339 sec)\n",
            "INFO:tensorflow:global_step/sec: 292.279\n",
            "INFO:tensorflow:loss = 0.015290935, step = 14301 (0.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.659\n",
            "INFO:tensorflow:loss = 0.023267284, step = 14401 (0.339 sec)\n",
            "INFO:tensorflow:global_step/sec: 312.902\n",
            "INFO:tensorflow:loss = 0.029080456, step = 14501 (0.319 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.885\n",
            "INFO:tensorflow:loss = 0.0066309506, step = 14601 (0.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 295.374\n",
            "INFO:tensorflow:loss = 0.014554034, step = 14701 (0.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 296.84\n",
            "INFO:tensorflow:loss = 0.025159702, step = 14801 (0.331 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.033\n",
            "INFO:tensorflow:loss = 0.006863335, step = 14901 (0.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.527\n",
            "INFO:tensorflow:loss = 0.027432691, step = 15001 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 313.181\n",
            "INFO:tensorflow:loss = 0.017495953, step = 15101 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.56\n",
            "INFO:tensorflow:loss = 0.034808278, step = 15201 (0.319 sec)\n",
            "INFO:tensorflow:global_step/sec: 293.534\n",
            "INFO:tensorflow:loss = 0.010874396, step = 15301 (0.347 sec)\n",
            "INFO:tensorflow:global_step/sec: 302.503\n",
            "INFO:tensorflow:loss = 0.023051986, step = 15401 (0.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 316.288\n",
            "INFO:tensorflow:loss = 0.010825807, step = 15501 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.869\n",
            "INFO:tensorflow:loss = 0.0074162823, step = 15601 (0.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 309.328\n",
            "INFO:tensorflow:loss = 0.019975116, step = 15701 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.788\n",
            "INFO:tensorflow:loss = 0.009082601, step = 15801 (0.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 294.388\n",
            "INFO:tensorflow:loss = 0.019911304, step = 15901 (0.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 283.071\n",
            "INFO:tensorflow:loss = 0.0064717117, step = 16001 (0.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 268.31\n",
            "INFO:tensorflow:loss = 0.015439136, step = 16101 (0.373 sec)\n",
            "INFO:tensorflow:global_step/sec: 289.045\n",
            "INFO:tensorflow:loss = 0.012270935, step = 16201 (0.348 sec)\n",
            "INFO:tensorflow:global_step/sec: 293.669\n",
            "INFO:tensorflow:loss = 0.01273854, step = 16301 (0.342 sec)\n",
            "INFO:tensorflow:global_step/sec: 283.341\n",
            "INFO:tensorflow:loss = 0.022958849, step = 16401 (0.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 276.624\n",
            "INFO:tensorflow:loss = 0.0075206086, step = 16501 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 278.555\n",
            "INFO:tensorflow:loss = 0.007870194, step = 16601 (0.365 sec)\n",
            "INFO:tensorflow:global_step/sec: 269.783\n",
            "INFO:tensorflow:loss = 0.010325557, step = 16701 (0.365 sec)\n",
            "INFO:tensorflow:global_step/sec: 286.118\n",
            "INFO:tensorflow:loss = 0.017929174, step = 16801 (0.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.435\n",
            "INFO:tensorflow:loss = 0.013098957, step = 16901 (0.348 sec)\n",
            "INFO:tensorflow:global_step/sec: 294.677\n",
            "INFO:tensorflow:loss = 0.015405331, step = 17001 (0.346 sec)\n",
            "INFO:tensorflow:global_step/sec: 303.07\n",
            "INFO:tensorflow:loss = 0.029375684, step = 17101 (0.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 319.317\n",
            "INFO:tensorflow:loss = 0.008764026, step = 17201 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 282.189\n",
            "INFO:tensorflow:loss = 0.017105272, step = 17301 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 289.201\n",
            "INFO:tensorflow:loss = 0.013647131, step = 17401 (0.346 sec)\n",
            "INFO:tensorflow:global_step/sec: 282.543\n",
            "INFO:tensorflow:loss = 0.02078329, step = 17501 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.761\n",
            "INFO:tensorflow:loss = 0.011425432, step = 17601 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 274.205\n",
            "INFO:tensorflow:loss = 0.013803905, step = 17701 (0.365 sec)\n",
            "INFO:tensorflow:global_step/sec: 292.659\n",
            "INFO:tensorflow:loss = 0.018978246, step = 17801 (0.339 sec)\n",
            "INFO:tensorflow:global_step/sec: 299.764\n",
            "INFO:tensorflow:loss = 0.01607509, step = 17901 (0.334 sec)\n",
            "INFO:tensorflow:global_step/sec: 288.385\n",
            "INFO:tensorflow:loss = 0.01358296, step = 18001 (0.348 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.268\n",
            "INFO:tensorflow:loss = 0.007865034, step = 18101 (0.346 sec)\n",
            "INFO:tensorflow:global_step/sec: 288.176\n",
            "INFO:tensorflow:loss = 0.003797894, step = 18201 (0.347 sec)\n",
            "INFO:tensorflow:global_step/sec: 270.359\n",
            "INFO:tensorflow:loss = 0.008301751, step = 18301 (0.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.404\n",
            "INFO:tensorflow:loss = 0.01423249, step = 18401 (0.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 278.091\n",
            "INFO:tensorflow:loss = 0.021098461, step = 18501 (0.359 sec)\n",
            "INFO:tensorflow:global_step/sec: 273.247\n",
            "INFO:tensorflow:loss = 0.013704575, step = 18601 (0.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.873\n",
            "INFO:tensorflow:loss = 0.009478845, step = 18701 (0.352 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.837\n",
            "INFO:tensorflow:loss = 0.011274919, step = 18801 (0.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 282.327\n",
            "INFO:tensorflow:loss = 0.010201776, step = 18901 (0.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.218\n",
            "INFO:tensorflow:loss = 0.007165487, step = 19001 (0.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.557\n",
            "INFO:tensorflow:loss = 0.0039766976, step = 19101 (0.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.218\n",
            "INFO:tensorflow:loss = 0.01712631, step = 19201 (0.362 sec)\n",
            "INFO:tensorflow:global_step/sec: 277.873\n",
            "INFO:tensorflow:loss = 0.012715159, step = 19301 (0.353 sec)\n",
            "INFO:tensorflow:global_step/sec: 278.863\n",
            "INFO:tensorflow:loss = 0.006681982, step = 19401 (0.362 sec)\n",
            "INFO:tensorflow:global_step/sec: 285.153\n",
            "INFO:tensorflow:loss = 0.02025607, step = 19501 (0.349 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.496\n",
            "INFO:tensorflow:loss = 0.010469958, step = 19601 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 277.801\n",
            "INFO:tensorflow:loss = 0.0070179612, step = 19701 (0.362 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.551\n",
            "INFO:tensorflow:loss = 0.019498315, step = 19801 (0.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 287.735\n",
            "INFO:tensorflow:loss = 0.053335886, step = 19901 (0.346 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmpv1dtw8fu/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.02332579.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x7f4000b2ba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmYLKo-Ixgcl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "0fc2fdc8-dab6-4e4a-f0ab-c73de0e3a05c"
      },
      "source": [
        "predict_function = tf.estimator.inputs.pandas_input_fn(x= x_test, y= y_test, shuffle= False)\n",
        "predicts = regressor.predict(input_fn= predict_function)\n",
        "\n",
        "predict_values = []\n",
        "for p in list(predicts):\n",
        "  predict_values.append(p['predictions'][0])\n",
        "\n",
        "predict_values = np.asarray(predict_values).reshape(-1,1)\n",
        "predict_values = scaler_preco.inverse_transform(predict_values)\n",
        "\n",
        "y_test2 = y_test.values.reshape(-1,1)\n",
        "y_test2 = scaler_preco.inverse_transform(y_test2)\n",
        "\n",
        "mae = mean_absolute_error(y_test2, predict_values)\n",
        "mae"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpv1dtw8fu/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109190.82051642746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    }
  ]
}