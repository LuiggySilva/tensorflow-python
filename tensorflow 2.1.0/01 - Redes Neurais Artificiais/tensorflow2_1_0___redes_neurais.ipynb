{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow2.1.0___redes_neurais.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUQ5FHev7W0N",
        "colab_type": "text"
      },
      "source": [
        "> # **TensorFlow  2.1.0** - ***01*** - *Redes Neurais Artificiais*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioKqonh3AcTd",
        "colab_type": "code",
        "outputId": "bba45659-f73d-46be-9a63-1a3b3ba1b916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist # https://www.kaggle.com/zalando-research/fashionmnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROXcDKi47yM6",
        "colab_type": "code",
        "outputId": "1fa77ef9-2691-4c49-d178-2d81216de531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "(x_training, y_training), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n09ds_hq8P4g",
        "colab_type": "code",
        "outputId": "63a29524-388a-49d4-84f8-e5a35524e2b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(' - Shapes:')\n",
        "print(f'x_training.shape -> {x_training.shape}')\n",
        "print(f'x_test.shape -> {x_test.shape}')\n",
        "print(f'y_training.shape -> {y_training.shape}')\n",
        "print(f'y_test.shape -> {y_test.shape}', end='\\n'*2)\n",
        "print(f' - Dado:\\nx_training[0] ->\\n{x_training[0]}', end='\\n'*2)\n",
        "print(f' - Dado:\\nnp.unique(y_training) -> {np.unique(y_training)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - Shapes:\n",
            "x_training.shape -> (60000, 28, 28)\n",
            "x_test.shape -> (10000, 28, 28)\n",
            "y_training.shape -> (60000,)\n",
            "y_test.shape -> (10000,)\n",
            "\n",
            " - Dado:\n",
            "x_training[0] ->\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "\n",
            " - Dado:\n",
            "np.unique(y_training) -> [0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00pLZMrC8xtC",
        "colab_type": "code",
        "outputId": "9fe62273-f74c-490e-bf8c-c72a90a1e8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Normalizando base de dados (Dividimos cada elemento(pixel) da base de dados por 255(maior valor de um pixel de uma imagem) para obter valores entre 0 e 1\n",
        "print(' - Normalizando base de dados\\n...')\n",
        "x_training = x_training / 255.0\n",
        "x_test = x_test / 255.0\n",
        "print(f' - Dado normalizado:\\nx_training[0] ->\\n{x_training[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - Normalizando base de dados\n",
            "...\n",
            " - Dado normalizado:\n",
            "x_training[0] ->\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
            "  0.         0.00392157 0.01568627 0.         0.         0.\n",
            "  0.         0.00392157 0.00392157 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725\n",
            "  0.21176471 0.         0.         0.         0.00392157 0.01176471\n",
            "  0.01568627 0.         0.         0.01176471]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.02352941 0.         0.4        0.8        0.69019608 0.5254902\n",
            "  0.56470588 0.48235294 0.09019608 0.         0.         0.\n",
            "  0.         0.04705882 0.03921569 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n",
            "  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n",
            "  0.30196078 0.50980392 0.28235294 0.05882353]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00392157\n",
            "  0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882\n",
            "  0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902\n",
            "  0.55294118 0.34509804 0.6745098  0.25882353]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
            "  0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922\n",
            "  0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922\n",
            "  0.48235294 0.76862745 0.89803922 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n",
            "  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n",
            "  0.8745098  0.96078431 0.67843137 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059\n",
            "  0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098\n",
            "  0.8627451  0.95294118 0.79215686 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.01176471 0.\n",
            "  0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118\n",
            "  0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255\n",
            "  0.88627451 0.77254902 0.81960784 0.20392157]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.02352941 0.\n",
            "  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n",
            "  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n",
            "  0.96078431 0.46666667 0.65490196 0.21960784]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.01568627 0.         0.\n",
            "  0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647\n",
            "  0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039\n",
            "  0.85098039 0.81960784 0.36078431 0.        ]\n",
            " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098\n",
            "  0.00784314 0.         0.         0.         0.         0.\n",
            "  0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353\n",
            "  0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725\n",
            "  0.85490196 1.         0.30196078 0.        ]\n",
            " [0.         0.01176471 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.24313725 0.56862745 0.8\n",
            "  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n",
            "  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n",
            "  0.87843137 0.95686275 0.62352941 0.        ]\n",
            " [0.         0.         0.         0.         0.07058824 0.17254902\n",
            "  0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824\n",
            "  0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078\n",
            "  0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902\n",
            "  0.91372549 0.93333333 0.84313725 0.        ]\n",
            " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667\n",
            "  0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784\n",
            "  0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098\n",
            "  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098\n",
            "  0.8627451  0.90980392 0.96470588 0.        ]\n",
            " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n",
            "  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n",
            "  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n",
            "  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n",
            "  0.87058824 0.89411765 0.88235294 0.        ]\n",
            " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922\n",
            "  0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725\n",
            "  0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353\n",
            "  0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098\n",
            "  0.8745098  0.87843137 0.89803922 0.11372549]\n",
            " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157\n",
            "  0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314\n",
            "  0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431\n",
            "  0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824\n",
            "  0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
            " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n",
            "  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n",
            "  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n",
            "  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n",
            "  0.70980392 0.80392157 0.80784314 0.45098039]\n",
            " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824\n",
            "  0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471\n",
            "  0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961\n",
            "  0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471\n",
            "  0.65490196 0.69411765 0.82352941 0.36078431]\n",
            " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961\n",
            "  0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549\n",
            "  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784\n",
            "  0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431\n",
            "  0.75294118 0.84705882 0.66666667 0.        ]\n",
            " [0.00784314 0.         0.         0.         0.25882353 0.78431373\n",
            "  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n",
            "  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n",
            "  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n",
            "  0.38823529 0.22745098 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431\n",
            "  0.1372549  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1WDDIExMQn3",
        "colab_type": "code",
        "outputId": "43592cea-6e6c-4a02-e554-2def5b54cd97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Remodelando base de dados (mudando de matriz para vetor)\n",
        "print(' - Remodelando base de dados')\n",
        "x_training = x_training.reshape(-1, 28 * 28)\n",
        "x_test     = x_test.reshape(-1, 28 * 28)\n",
        "print(f'x_training.shape -> {x_training.shape}')\n",
        "print(f'x_test.shape -> {x_test.shape}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - Remodelando base de dados\n",
            "x_training.shape -> (60000, 784)\n",
            "x_test.shape -> (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HC1ZfFOOpzE",
        "colab_type": "code",
        "outputId": "9558664f-e9be-42b3-d188-4eb0ef4f3816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "# Construindo a rede neural\n",
        "neuronios_entrada = 784\n",
        "neuronios_oculta = 128\n",
        "neuronios_saida = 10\n",
        "taxa_dropout = 0.2\n",
        "\n",
        "# Criando o modelo\n",
        "model = tf.keras.models.Sequential()\n",
        "# Camada de entrada e camada oculta 1\n",
        "model.add(tf.keras.layers.Dense(units= neuronios_oculta, activation= 'relu', input_shape= (neuronios_entrada, )))\n",
        "# Adicionando Dropout 1\n",
        "model.add(tf.keras.layers.Dropout(taxa_dropout))\n",
        "# Adicionando mais camadas ocultas\n",
        "model.add(tf.keras.layers.Dense(units= neuronios_oculta, activation= 'relu')) # camada oculta 2\n",
        "model.add(tf.keras.layers.Dropout(taxa_dropout)) # Dropout 2\n",
        "model.add(tf.keras.layers.Dense(units= neuronios_oculta, activation= 'relu')) # camada oculta 3\n",
        "model.add(tf.keras.layers.Dropout(taxa_dropout)) # Dropout 3\n",
        "model.add(tf.keras.layers.Dense(units= neuronios_oculta, activation= 'relu')) # camada oculta 4\n",
        "model.add(tf.keras.layers.Dropout(taxa_dropout)) # Dropout 4\n",
        "# Camada de saida\n",
        "model.add(tf.keras.layers.Dense(units= neuronios_saida, activation= 'softmax'))\n",
        "# Compilando o modelo ('sparse porque a saida não é no formato OneHotEncode')\n",
        "model.compile(optimizer= 'adam', loss= 'sparse_categorical_crossentropy', metrics= ['sparse_categorical_accuracy'])\n",
        "print(' - Resumo do modelo')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - Resumo do modelo\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 151,306\n",
            "Trainable params: 151,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46hLw5zCO0A9",
        "colab_type": "code",
        "outputId": "8a43af38-6f03-4f1b-9b66-efc4d3d6719d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "# Treinamento do modelo\n",
        "print(' - Treinamento do modelo')\n",
        "model.fit(x_training, y_training, epochs= 20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - Treinamento do modelo\n",
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.6296 - sparse_categorical_accuracy: 0.7734\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4610 - sparse_categorical_accuracy: 0.8361\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4200 - sparse_categorical_accuracy: 0.8501\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4035 - sparse_categorical_accuracy: 0.8551\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3874 - sparse_categorical_accuracy: 0.8608\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3710 - sparse_categorical_accuracy: 0.8680\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3629 - sparse_categorical_accuracy: 0.8695\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3554 - sparse_categorical_accuracy: 0.8721\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3485 - sparse_categorical_accuracy: 0.8755\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3417 - sparse_categorical_accuracy: 0.8779\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3383 - sparse_categorical_accuracy: 0.8778\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3328 - sparse_categorical_accuracy: 0.8795\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3262 - sparse_categorical_accuracy: 0.8825\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3231 - sparse_categorical_accuracy: 0.8848\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.3197 - sparse_categorical_accuracy: 0.8856\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.3175 - sparse_categorical_accuracy: 0.8850\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3103 - sparse_categorical_accuracy: 0.8879\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3117 - sparse_categorical_accuracy: 0.8884\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3051 - sparse_categorical_accuracy: 0.8881\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3067 - sparse_categorical_accuracy: 0.8893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2940372f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMqSxBWXO2C5",
        "colab_type": "code",
        "outputId": "9f91d619-cdc5-4db2-d476-97ddce13f6af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Avaliando o modelo\n",
        "print(' - Avaliando o modelo')\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Taxa de acerto -> {test_accuracy}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - Avaliando o modelo\n",
            "10000/10000 [==============================] - 1s 66us/sample - loss: 0.3400 - sparse_categorical_accuracy: 0.8820\n",
            "Taxa de acerto -> 0.8820000290870667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sdi2015O3pt",
        "colab_type": "code",
        "outputId": "142054ec-d027-4bb2-f9fa-6c1176a60504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Salvando o modelo\n",
        "print(' - Salvando o modelo ...')\n",
        "model_json = model.to_json()\n",
        "with open('fashion_model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "    print('Modelo salvo!')\n",
        "\n",
        "# Salvando os pesos'\n",
        "print('\\n'*2 + ' - Salvando os pesos do modelo ...')\n",
        "model.save_weights('fashion_model.h5')\n",
        "print('Pesos do modelos salvos!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - Salvando o modelo ...\n",
            "Modelo salvo!\n",
            "\n",
            "\n",
            " - Salvando os pesos do modelo ...\n",
            "Pesos do modelos salvos!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}