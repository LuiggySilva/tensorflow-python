# -*- coding: utf-8 -*-
"""tensorflow2.1.0___tensorflow_transform.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q9wnesdsYHn9WxzVPRtqd48a6SKVrAGT

> # **TensorFlow  2.1.0** - ***07*** - *Pré-processamento de dados com Tensorflow Transform*
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install -Uq apache_beam==2.17.0
import apache_beam as beam
import apache_beam.io.iobase
!pip install -q tensorflow_data_validation==0.21.2
import tensorflow_data_validation as tfdv
!pip install tensorflow-transform

try:
#   %tensorflow_version 2.x
except:
  pass

import tempfile
import tensorflow as tf
import tensorflow_transform as tft
import tensorflow_transform.beam.impl as tft_beam
import pandas as pd

from __future__ import print_function
from tensorflow_transform.tf_metadata import dataset_metadata, dataset_schema

# carregando e analisando dados
# nivel de poluiçao (soot) pela quantidade dos elementos (pm10, no2, so2) no ar
dataset = pd.read_csv('original.csv')
dataset.head()

features = dataset.drop('Date', axis= 1)
features.head()

# convertendo dataframe (features) para dicionario
dict_features = list(features.to_dict('index').values())
dict_features[0:10]

# definindo metadados
data_metadata = dataset_metadata.DatasetMetadata(dataset_schema.from_feature_spec({
  'pm10':tf.FixedLenFeature([], tf.float32),
  'no2':tf.FixedLenFeature([], tf.float32),
  'so2':tf.FixedLenFeature([], tf.float32),
  'soot':tf.FixedLenFeature([], tf.float32)
}))

data_metadata

# função de pré-processamento
def preprocessing_fn(inputs):
  pm10 = inputs['pm10']
  no2  = inputs['no2']
  so2  = inputs['so2']
  soot = inputs['soot']
  
  pm10_normalized = tft.scale_to_0_1(pm10)
  no2_normalized  = no2 - tft.mean(no2)
  so2_normalized  = no2 - tft.mean(so2)
  soot_normalized = tft.scale_by_min_max(soot)

  return {
    'pm10_normalized': pm10_normalized,
    'no2_normalized' : no2_normalized,
    'so2_normalized' : so2_normalized,
    'soot_normalized': soot_normalized
  }

# unindo a codificação
def data_transform():
  with tft_beam.Context(temp_dir= tempfile.mkdtemp()):
    transformed_dataset, transform_fn = ((dict_features, data_metadata) | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))
  transformed_data, transformed_metadata = transformed_dataset

  for i in range(len(transformed_data)):
    print("Initial: ", dict_features[i])
    print("Transformed: ", transformed_data[i])

data_transform()